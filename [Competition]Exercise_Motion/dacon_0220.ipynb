{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "signal-control",
   "metadata": {
    "executionInfo": {
     "elapsed": 2512,
     "status": "ok",
     "timestamp": 1613799786330,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "signal-control"
   },
   "outputs": [],
   "source": [
    "# 분석\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 시각화\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, roc_auc_score,precision_score,recall_score, roc_curve, classification_report,precision_recall_curve\n",
    "from sklearn.metrics import make_scorer\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Uje8lBzL-4hi",
   "metadata": {
    "id": "Uje8lBzL-4hi"
   },
   "source": [
    "### 코랩이용시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seasonal-compatibility",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16627,
     "status": "ok",
     "timestamp": 1613799800495,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "seasonal-compatibility",
    "outputId": "fa253d6a-6dc7-4d62-9fd9-bdf95d26fb06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "little-helmet",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "executionInfo": {
     "elapsed": 7067,
     "status": "ok",
     "timestamp": 1613799808316,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "little-helmet",
    "outputId": "24ff7ce4-c3a3-489f-943a-c64229ef92ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.206087</td>\n",
       "      <td>-0.179371</td>\n",
       "      <td>-0.148447</td>\n",
       "      <td>-0.591608</td>\n",
       "      <td>-30.549010</td>\n",
       "      <td>-31.676112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.287696</td>\n",
       "      <td>-0.198974</td>\n",
       "      <td>-0.182444</td>\n",
       "      <td>0.303100</td>\n",
       "      <td>-39.139103</td>\n",
       "      <td>-24.927216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.304609</td>\n",
       "      <td>-0.195114</td>\n",
       "      <td>-0.253382</td>\n",
       "      <td>-3.617278</td>\n",
       "      <td>-44.122565</td>\n",
       "      <td>-25.019629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  time     acc_x     acc_y     acc_z      gy_x       gy_y       gy_z\n",
       "0   0     0  1.206087 -0.179371 -0.148447 -0.591608 -30.549010 -31.676112\n",
       "1   0     1  1.287696 -0.198974 -0.182444  0.303100 -39.139103 -24.927216\n",
       "2   0     2  1.304609 -0.195114 -0.253382 -3.617278 -44.122565 -25.019629"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>label_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>Shoulder Press (dumbbell)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>Non-Exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Biceps Curl (band)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                 label_desc\n",
       "0   0     37  Shoulder Press (dumbbell)\n",
       "1   1     26               Non-Exercise\n",
       "2   2      3         Biceps Curl (band)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3125</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.628100</td>\n",
       "      <td>-0.160155</td>\n",
       "      <td>0.151487</td>\n",
       "      <td>49.665357</td>\n",
       "      <td>88.435961</td>\n",
       "      <td>13.597668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3125</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.462548</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>-0.053726</td>\n",
       "      <td>56.953059</td>\n",
       "      <td>96.185341</td>\n",
       "      <td>16.278458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3125</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.363481</td>\n",
       "      <td>-0.091789</td>\n",
       "      <td>-0.130004</td>\n",
       "      <td>29.557396</td>\n",
       "      <td>93.836453</td>\n",
       "      <td>13.329043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  time     acc_x     acc_y     acc_z       gy_x       gy_y       gy_z\n",
       "0  3125     0 -0.628100 -0.160155  0.151487  49.665357  88.435961  13.597668\n",
       "1  3125     1 -0.462548  0.012462 -0.053726  56.953059  96.185341  16.278458\n",
       "2  3125     2 -0.363481 -0.091789 -0.130004  29.557396  93.836453  13.329043"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_path = '/content/drive/MyDrive/Colab Notebooks/Dacon/'\n",
    "X_train = pd.read_csv(d_path + 'train_features.csv')\n",
    "y_train = pd.read_csv(d_path + 'train_labels.csv')\n",
    "X_test = pd.read_csv(d_path + 'test_features.csv')\n",
    "submission = pd.read_csv(d_path + 'sample_submission.csv')\n",
    "\n",
    "display(X_train.head(3))\n",
    "display(y_train.head(3))\n",
    "display(X_test.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rhQKBRMt-8Zs",
   "metadata": {
    "id": "rhQKBRMt-8Zs"
   },
   "source": [
    "### 쥬피터 이용시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-tooth",
   "metadata": {
    "id": "associate-tooth"
   },
   "outputs": [],
   "source": [
    "# X_train = pd.read_csv('train_features.csv')\n",
    "# y_train = pd.read_csv( 'train_labels.csv')\n",
    "# X_test = pd.read_csv('test_features.csv')\n",
    "# submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tn5UqUV4-_0z",
   "metadata": {
    "id": "tn5UqUV4-_0z"
   },
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mJpX-4nv_KgL",
   "metadata": {
    "id": "mJpX-4nv_KgL"
   },
   "source": [
    "#### X_train의 데이터를 통해서 id와 time을 제외한 피쳐를 대상으로 id를 기준으로 잡아 합, 평균, 중앙값, 최소값, 최대값을 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "honey-basement",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "executionInfo": {
     "elapsed": 2028,
     "status": "ok",
     "timestamp": 1613799812949,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "honey-basement",
    "outputId": "f32c6f2d-ae6d-45fe-b9b0-a2e983a09003"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">sum</th>\n",
       "      <th colspan=\"6\" halign=\"left\">mean</th>\n",
       "      <th colspan=\"6\" halign=\"left\">median</th>\n",
       "      <th colspan=\"6\" halign=\"left\">min</th>\n",
       "      <th colspan=\"6\" halign=\"left\">max</th>\n",
       "      <th colspan=\"6\" halign=\"left\">std</th>\n",
       "      <th colspan=\"6\" halign=\"left\">var</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>558.797337</td>\n",
       "      <td>-131.082711</td>\n",
       "      <td>-222.252919</td>\n",
       "      <td>-1119.161589</td>\n",
       "      <td>-2015.703683</td>\n",
       "      <td>709.264425</td>\n",
       "      <td>0.931329</td>\n",
       "      <td>-0.218471</td>\n",
       "      <td>-0.370422</td>\n",
       "      <td>-1.865269</td>\n",
       "      <td>-3.359506</td>\n",
       "      <td>1.182107</td>\n",
       "      <td>0.956149</td>\n",
       "      <td>-0.240638</td>\n",
       "      <td>-0.346749</td>\n",
       "      <td>-1.273569</td>\n",
       "      <td>-2.362230</td>\n",
       "      <td>1.913286</td>\n",
       "      <td>0.591940</td>\n",
       "      <td>-0.624113</td>\n",
       "      <td>-0.786336</td>\n",
       "      <td>-46.254836</td>\n",
       "      <td>-85.887677</td>\n",
       "      <td>-79.930029</td>\n",
       "      <td>1.344268</td>\n",
       "      <td>0.176871</td>\n",
       "      <td>-0.054876</td>\n",
       "      <td>31.644123</td>\n",
       "      <td>69.847244</td>\n",
       "      <td>55.953827</td>\n",
       "      <td>0.191479</td>\n",
       "      <td>0.177131</td>\n",
       "      <td>0.135131</td>\n",
       "      <td>13.284216</td>\n",
       "      <td>24.300479</td>\n",
       "      <td>25.275185</td>\n",
       "      <td>0.036664</td>\n",
       "      <td>0.031375</td>\n",
       "      <td>0.018260</td>\n",
       "      <td>176.470384</td>\n",
       "      <td>590.513292</td>\n",
       "      <td>638.834979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-459.948117</td>\n",
       "      <td>-190.354639</td>\n",
       "      <td>-2.534051</td>\n",
       "      <td>6642.960123</td>\n",
       "      <td>1044.284884</td>\n",
       "      <td>835.976169</td>\n",
       "      <td>-0.766580</td>\n",
       "      <td>-0.317258</td>\n",
       "      <td>-0.004223</td>\n",
       "      <td>11.071600</td>\n",
       "      <td>1.740475</td>\n",
       "      <td>1.393294</td>\n",
       "      <td>-0.805767</td>\n",
       "      <td>-0.228905</td>\n",
       "      <td>-0.034583</td>\n",
       "      <td>3.810650</td>\n",
       "      <td>8.043707</td>\n",
       "      <td>-0.655819</td>\n",
       "      <td>-2.156208</td>\n",
       "      <td>-1.295598</td>\n",
       "      <td>-1.019531</td>\n",
       "      <td>-325.328531</td>\n",
       "      <td>-315.096003</td>\n",
       "      <td>-270.980823</td>\n",
       "      <td>1.234020</td>\n",
       "      <td>0.700065</td>\n",
       "      <td>0.888661</td>\n",
       "      <td>286.624363</td>\n",
       "      <td>389.608060</td>\n",
       "      <td>340.170199</td>\n",
       "      <td>0.495528</td>\n",
       "      <td>0.336415</td>\n",
       "      <td>0.499395</td>\n",
       "      <td>79.244561</td>\n",
       "      <td>96.005289</td>\n",
       "      <td>75.545343</td>\n",
       "      <td>0.245548</td>\n",
       "      <td>0.113175</td>\n",
       "      <td>0.249396</td>\n",
       "      <td>6279.700472</td>\n",
       "      <td>9217.015511</td>\n",
       "      <td>5707.098884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.901616</td>\n",
       "      <td>-49.441742</td>\n",
       "      <td>375.607013</td>\n",
       "      <td>-5083.770868</td>\n",
       "      <td>358.725917</td>\n",
       "      <td>1831.974458</td>\n",
       "      <td>0.039836</td>\n",
       "      <td>-0.082403</td>\n",
       "      <td>0.626012</td>\n",
       "      <td>-8.472951</td>\n",
       "      <td>0.597877</td>\n",
       "      <td>3.053291</td>\n",
       "      <td>0.140667</td>\n",
       "      <td>-0.062598</td>\n",
       "      <td>0.634781</td>\n",
       "      <td>-8.112557</td>\n",
       "      <td>19.306132</td>\n",
       "      <td>3.568888</td>\n",
       "      <td>-1.142847</td>\n",
       "      <td>-0.690990</td>\n",
       "      <td>0.073846</td>\n",
       "      <td>-164.779067</td>\n",
       "      <td>-249.953944</td>\n",
       "      <td>-44.192071</td>\n",
       "      <td>1.219836</td>\n",
       "      <td>0.650645</td>\n",
       "      <td>1.332992</td>\n",
       "      <td>73.525082</td>\n",
       "      <td>297.320834</td>\n",
       "      <td>55.642836</td>\n",
       "      <td>0.711972</td>\n",
       "      <td>0.147127</td>\n",
       "      <td>0.248807</td>\n",
       "      <td>25.422926</td>\n",
       "      <td>118.956646</td>\n",
       "      <td>13.920337</td>\n",
       "      <td>0.506904</td>\n",
       "      <td>0.021646</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>646.325142</td>\n",
       "      <td>14150.683677</td>\n",
       "      <td>193.775778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sum                          ...          var                           \n",
       "         acc_x       acc_y       acc_z  ...         gy_x          gy_y         gy_z\n",
       "id                                      ...                                        \n",
       "0   558.797337 -131.082711 -222.252919  ...   176.470384    590.513292   638.834979\n",
       "1  -459.948117 -190.354639   -2.534051  ...  6279.700472   9217.015511  5707.098884\n",
       "2    23.901616  -49.441742  375.607013  ...   646.325142  14150.683677   193.775778\n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">sum</th>\n",
       "      <th colspan=\"6\" halign=\"left\">mean</th>\n",
       "      <th colspan=\"6\" halign=\"left\">median</th>\n",
       "      <th colspan=\"6\" halign=\"left\">min</th>\n",
       "      <th colspan=\"6\" halign=\"left\">max</th>\n",
       "      <th colspan=\"6\" halign=\"left\">std</th>\n",
       "      <th colspan=\"6\" halign=\"left\">var</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3125</th>\n",
       "      <td>-611.238360</td>\n",
       "      <td>-11.744605</td>\n",
       "      <td>-139.355669</td>\n",
       "      <td>-1911.076959</td>\n",
       "      <td>1639.123438</td>\n",
       "      <td>-1200.410049</td>\n",
       "      <td>-1.018731</td>\n",
       "      <td>-0.019574</td>\n",
       "      <td>-0.232259</td>\n",
       "      <td>-3.185128</td>\n",
       "      <td>2.731872</td>\n",
       "      <td>-2.000683</td>\n",
       "      <td>-1.064222</td>\n",
       "      <td>-0.005735</td>\n",
       "      <td>-0.268442</td>\n",
       "      <td>-3.770150</td>\n",
       "      <td>0.108956</td>\n",
       "      <td>-1.607847</td>\n",
       "      <td>-1.564000</td>\n",
       "      <td>-0.470937</td>\n",
       "      <td>-0.573836</td>\n",
       "      <td>-50.429364</td>\n",
       "      <td>-81.607713</td>\n",
       "      <td>-35.446915</td>\n",
       "      <td>-0.275446</td>\n",
       "      <td>0.228040</td>\n",
       "      <td>0.286182</td>\n",
       "      <td>56.953059</td>\n",
       "      <td>96.185341</td>\n",
       "      <td>49.981455</td>\n",
       "      <td>0.236232</td>\n",
       "      <td>0.091641</td>\n",
       "      <td>0.174672</td>\n",
       "      <td>12.897967</td>\n",
       "      <td>31.993022</td>\n",
       "      <td>12.251648</td>\n",
       "      <td>0.055806</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.030510</td>\n",
       "      <td>166.357553</td>\n",
       "      <td>1023.553453</td>\n",
       "      <td>150.102867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>-313.705824</td>\n",
       "      <td>367.296809</td>\n",
       "      <td>-42.655405</td>\n",
       "      <td>-10644.915365</td>\n",
       "      <td>4184.863263</td>\n",
       "      <td>-2162.747150</td>\n",
       "      <td>-0.522843</td>\n",
       "      <td>0.612161</td>\n",
       "      <td>-0.071092</td>\n",
       "      <td>-17.741526</td>\n",
       "      <td>6.974772</td>\n",
       "      <td>-3.604579</td>\n",
       "      <td>-0.677411</td>\n",
       "      <td>0.606215</td>\n",
       "      <td>-0.026089</td>\n",
       "      <td>-14.305258</td>\n",
       "      <td>-0.974696</td>\n",
       "      <td>-10.833508</td>\n",
       "      <td>-1.929033</td>\n",
       "      <td>-0.200678</td>\n",
       "      <td>-1.212052</td>\n",
       "      <td>-273.572486</td>\n",
       "      <td>-97.100707</td>\n",
       "      <td>-147.597574</td>\n",
       "      <td>0.627571</td>\n",
       "      <td>1.708743</td>\n",
       "      <td>0.671876</td>\n",
       "      <td>132.830402</td>\n",
       "      <td>241.240196</td>\n",
       "      <td>169.417650</td>\n",
       "      <td>0.539688</td>\n",
       "      <td>0.333015</td>\n",
       "      <td>0.383800</td>\n",
       "      <td>51.625096</td>\n",
       "      <td>45.706311</td>\n",
       "      <td>61.604867</td>\n",
       "      <td>0.291264</td>\n",
       "      <td>0.110899</td>\n",
       "      <td>0.147302</td>\n",
       "      <td>2665.150566</td>\n",
       "      <td>2089.066820</td>\n",
       "      <td>3795.159662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>304.167948</td>\n",
       "      <td>542.291164</td>\n",
       "      <td>-84.658968</td>\n",
       "      <td>-1307.846921</td>\n",
       "      <td>-1350.871152</td>\n",
       "      <td>-235.904841</td>\n",
       "      <td>0.506947</td>\n",
       "      <td>0.903819</td>\n",
       "      <td>-0.141098</td>\n",
       "      <td>-2.179745</td>\n",
       "      <td>-2.251452</td>\n",
       "      <td>-0.393175</td>\n",
       "      <td>0.497370</td>\n",
       "      <td>0.931239</td>\n",
       "      <td>-0.156647</td>\n",
       "      <td>0.476247</td>\n",
       "      <td>-2.319172</td>\n",
       "      <td>-3.087735</td>\n",
       "      <td>-0.792916</td>\n",
       "      <td>0.219008</td>\n",
       "      <td>-0.484614</td>\n",
       "      <td>-99.799971</td>\n",
       "      <td>-98.420987</td>\n",
       "      <td>-154.477074</td>\n",
       "      <td>2.972063</td>\n",
       "      <td>1.941820</td>\n",
       "      <td>0.644154</td>\n",
       "      <td>160.426058</td>\n",
       "      <td>74.530763</td>\n",
       "      <td>97.211730</td>\n",
       "      <td>0.219934</td>\n",
       "      <td>0.191485</td>\n",
       "      <td>0.152077</td>\n",
       "      <td>22.770845</td>\n",
       "      <td>13.467885</td>\n",
       "      <td>23.041463</td>\n",
       "      <td>0.048371</td>\n",
       "      <td>0.036666</td>\n",
       "      <td>0.023128</td>\n",
       "      <td>518.511372</td>\n",
       "      <td>181.383940</td>\n",
       "      <td>530.909012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sum                          ...          var                          \n",
       "           acc_x       acc_y       acc_z  ...         gy_x         gy_y         gy_z\n",
       "id                                        ...                                       \n",
       "3125 -611.238360  -11.744605 -139.355669  ...   166.357553  1023.553453   150.102867\n",
       "3126 -313.705824  367.296809  -42.655405  ...  2665.150566  2089.066820  3795.159662\n",
       "3127  304.167948  542.291164  -84.658968  ...   518.511372   181.383940   530.909012\n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_pivot_train = pd.pivot_table(data = X_train, # X_train의 데이터를 통해서\n",
    "                               values = X_train.columns[2:],  # id와 time을 제외한 피쳐를 대상으로\n",
    "                               index = 'id', # id를 기준으로 잡아\n",
    "                               aggfunc = ['sum','mean',         # 합, 평균\n",
    "                                          'median','min','max', # 중앙값 최소값, 최대값\n",
    "                                          'std','var'           # 베셀 보정 표본 표준편차, 비편향 편차 의 값을 구합니다.\n",
    "                                         ]\n",
    "                              )\n",
    "\n",
    "X_pivot_test = pd.pivot_table(data = X_test, \n",
    "                               values = X_test.columns[2:], \n",
    "                               index = 'id', \n",
    "                               aggfunc = ['sum','mean',        \n",
    "                                          'median','min','max',\n",
    "                                          'std','var'          \n",
    "                                         ]\n",
    "                              )\n",
    "\n",
    "display(X_pivot_train.head(3))\n",
    "display(X_pivot_test.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "agreed-shooting",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1613799815155,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "agreed-shooting",
    "outputId": "dc31dfa5-fa3e-4d83-fb62-c3dee093cb64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('sum', 'acc_x'),\n",
       "            ('sum', 'acc_y'),\n",
       "            ('sum', 'acc_z'),\n",
       "            ('sum',  'gy_x'),\n",
       "            ('sum',  'gy_y')],\n",
       "           )"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pivot_train.columns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "inclusive-reference",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "executionInfo": {
     "elapsed": 584,
     "status": "ok",
     "timestamp": 1613799816041,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "inclusive-reference",
    "outputId": "700335f1-bfef-47ec-c9f6-3af66f37d55b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_acc_x</th>\n",
       "      <th>sum_acc_y</th>\n",
       "      <th>sum_acc_z</th>\n",
       "      <th>sum_gy_x</th>\n",
       "      <th>sum_gy_y</th>\n",
       "      <th>sum_gy_z</th>\n",
       "      <th>mean_acc_x</th>\n",
       "      <th>mean_acc_y</th>\n",
       "      <th>mean_acc_z</th>\n",
       "      <th>mean_gy_x</th>\n",
       "      <th>mean_gy_y</th>\n",
       "      <th>mean_gy_z</th>\n",
       "      <th>median_acc_x</th>\n",
       "      <th>median_acc_y</th>\n",
       "      <th>median_acc_z</th>\n",
       "      <th>median_gy_x</th>\n",
       "      <th>median_gy_y</th>\n",
       "      <th>median_gy_z</th>\n",
       "      <th>min_acc_x</th>\n",
       "      <th>min_acc_y</th>\n",
       "      <th>min_acc_z</th>\n",
       "      <th>min_gy_x</th>\n",
       "      <th>min_gy_y</th>\n",
       "      <th>min_gy_z</th>\n",
       "      <th>max_acc_x</th>\n",
       "      <th>max_acc_y</th>\n",
       "      <th>max_acc_z</th>\n",
       "      <th>max_gy_x</th>\n",
       "      <th>max_gy_y</th>\n",
       "      <th>max_gy_z</th>\n",
       "      <th>std_acc_x</th>\n",
       "      <th>std_acc_y</th>\n",
       "      <th>std_acc_z</th>\n",
       "      <th>std_gy_x</th>\n",
       "      <th>std_gy_y</th>\n",
       "      <th>std_gy_z</th>\n",
       "      <th>var_acc_x</th>\n",
       "      <th>var_acc_y</th>\n",
       "      <th>var_acc_z</th>\n",
       "      <th>var_gy_x</th>\n",
       "      <th>var_gy_y</th>\n",
       "      <th>var_gy_z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>558.797337</td>\n",
       "      <td>-131.082711</td>\n",
       "      <td>-222.252919</td>\n",
       "      <td>-1119.161589</td>\n",
       "      <td>-2015.703683</td>\n",
       "      <td>709.264425</td>\n",
       "      <td>0.931329</td>\n",
       "      <td>-0.218471</td>\n",
       "      <td>-0.370422</td>\n",
       "      <td>-1.865269</td>\n",
       "      <td>-3.359506</td>\n",
       "      <td>1.182107</td>\n",
       "      <td>0.956149</td>\n",
       "      <td>-0.240638</td>\n",
       "      <td>-0.346749</td>\n",
       "      <td>-1.273569</td>\n",
       "      <td>-2.362230</td>\n",
       "      <td>1.913286</td>\n",
       "      <td>0.591940</td>\n",
       "      <td>-0.624113</td>\n",
       "      <td>-0.786336</td>\n",
       "      <td>-46.254836</td>\n",
       "      <td>-85.887677</td>\n",
       "      <td>-79.930029</td>\n",
       "      <td>1.344268</td>\n",
       "      <td>0.176871</td>\n",
       "      <td>-0.054876</td>\n",
       "      <td>31.644123</td>\n",
       "      <td>69.847244</td>\n",
       "      <td>55.953827</td>\n",
       "      <td>0.191479</td>\n",
       "      <td>0.177131</td>\n",
       "      <td>0.135131</td>\n",
       "      <td>13.284216</td>\n",
       "      <td>24.300479</td>\n",
       "      <td>25.275185</td>\n",
       "      <td>0.036664</td>\n",
       "      <td>0.031375</td>\n",
       "      <td>0.018260</td>\n",
       "      <td>176.470384</td>\n",
       "      <td>590.513292</td>\n",
       "      <td>638.834979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-459.948117</td>\n",
       "      <td>-190.354639</td>\n",
       "      <td>-2.534051</td>\n",
       "      <td>6642.960123</td>\n",
       "      <td>1044.284884</td>\n",
       "      <td>835.976169</td>\n",
       "      <td>-0.766580</td>\n",
       "      <td>-0.317258</td>\n",
       "      <td>-0.004223</td>\n",
       "      <td>11.071600</td>\n",
       "      <td>1.740475</td>\n",
       "      <td>1.393294</td>\n",
       "      <td>-0.805767</td>\n",
       "      <td>-0.228905</td>\n",
       "      <td>-0.034583</td>\n",
       "      <td>3.810650</td>\n",
       "      <td>8.043707</td>\n",
       "      <td>-0.655819</td>\n",
       "      <td>-2.156208</td>\n",
       "      <td>-1.295598</td>\n",
       "      <td>-1.019531</td>\n",
       "      <td>-325.328531</td>\n",
       "      <td>-315.096003</td>\n",
       "      <td>-270.980823</td>\n",
       "      <td>1.234020</td>\n",
       "      <td>0.700065</td>\n",
       "      <td>0.888661</td>\n",
       "      <td>286.624363</td>\n",
       "      <td>389.608060</td>\n",
       "      <td>340.170199</td>\n",
       "      <td>0.495528</td>\n",
       "      <td>0.336415</td>\n",
       "      <td>0.499395</td>\n",
       "      <td>79.244561</td>\n",
       "      <td>96.005289</td>\n",
       "      <td>75.545343</td>\n",
       "      <td>0.245548</td>\n",
       "      <td>0.113175</td>\n",
       "      <td>0.249396</td>\n",
       "      <td>6279.700472</td>\n",
       "      <td>9217.015511</td>\n",
       "      <td>5707.098884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.901616</td>\n",
       "      <td>-49.441742</td>\n",
       "      <td>375.607013</td>\n",
       "      <td>-5083.770868</td>\n",
       "      <td>358.725917</td>\n",
       "      <td>1831.974458</td>\n",
       "      <td>0.039836</td>\n",
       "      <td>-0.082403</td>\n",
       "      <td>0.626012</td>\n",
       "      <td>-8.472951</td>\n",
       "      <td>0.597877</td>\n",
       "      <td>3.053291</td>\n",
       "      <td>0.140667</td>\n",
       "      <td>-0.062598</td>\n",
       "      <td>0.634781</td>\n",
       "      <td>-8.112557</td>\n",
       "      <td>19.306132</td>\n",
       "      <td>3.568888</td>\n",
       "      <td>-1.142847</td>\n",
       "      <td>-0.690990</td>\n",
       "      <td>0.073846</td>\n",
       "      <td>-164.779067</td>\n",
       "      <td>-249.953944</td>\n",
       "      <td>-44.192071</td>\n",
       "      <td>1.219836</td>\n",
       "      <td>0.650645</td>\n",
       "      <td>1.332992</td>\n",
       "      <td>73.525082</td>\n",
       "      <td>297.320834</td>\n",
       "      <td>55.642836</td>\n",
       "      <td>0.711972</td>\n",
       "      <td>0.147127</td>\n",
       "      <td>0.248807</td>\n",
       "      <td>25.422926</td>\n",
       "      <td>118.956646</td>\n",
       "      <td>13.920337</td>\n",
       "      <td>0.506904</td>\n",
       "      <td>0.021646</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>646.325142</td>\n",
       "      <td>14150.683677</td>\n",
       "      <td>193.775778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-532.621192</td>\n",
       "      <td>-52.600737</td>\n",
       "      <td>136.413976</td>\n",
       "      <td>10646.500409</td>\n",
       "      <td>2880.558352</td>\n",
       "      <td>-3521.938833</td>\n",
       "      <td>-0.887702</td>\n",
       "      <td>-0.087668</td>\n",
       "      <td>0.227357</td>\n",
       "      <td>17.744167</td>\n",
       "      <td>4.800931</td>\n",
       "      <td>-5.869898</td>\n",
       "      <td>-0.880343</td>\n",
       "      <td>-0.054577</td>\n",
       "      <td>0.231537</td>\n",
       "      <td>8.229938</td>\n",
       "      <td>1.783260</td>\n",
       "      <td>-3.853078</td>\n",
       "      <td>-1.417751</td>\n",
       "      <td>-0.540827</td>\n",
       "      <td>-0.257124</td>\n",
       "      <td>-69.419166</td>\n",
       "      <td>-82.537304</td>\n",
       "      <td>-85.600536</td>\n",
       "      <td>-0.622250</td>\n",
       "      <td>0.283721</td>\n",
       "      <td>0.598814</td>\n",
       "      <td>192.765368</td>\n",
       "      <td>159.083788</td>\n",
       "      <td>56.456908</td>\n",
       "      <td>0.130899</td>\n",
       "      <td>0.194008</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>42.928860</td>\n",
       "      <td>36.953466</td>\n",
       "      <td>23.647153</td>\n",
       "      <td>0.017134</td>\n",
       "      <td>0.037639</td>\n",
       "      <td>0.042387</td>\n",
       "      <td>1842.887012</td>\n",
       "      <td>1365.558625</td>\n",
       "      <td>559.187841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-395.410844</td>\n",
       "      <td>-202.240064</td>\n",
       "      <td>121.654507</td>\n",
       "      <td>-2891.782899</td>\n",
       "      <td>5791.027696</td>\n",
       "      <td>2672.029417</td>\n",
       "      <td>-0.659018</td>\n",
       "      <td>-0.337067</td>\n",
       "      <td>0.202758</td>\n",
       "      <td>-4.819638</td>\n",
       "      <td>9.651713</td>\n",
       "      <td>4.453382</td>\n",
       "      <td>-0.941146</td>\n",
       "      <td>-0.168467</td>\n",
       "      <td>0.293556</td>\n",
       "      <td>-1.292194</td>\n",
       "      <td>0.977772</td>\n",
       "      <td>-0.750283</td>\n",
       "      <td>-2.429109</td>\n",
       "      <td>-2.055076</td>\n",
       "      <td>-1.250483</td>\n",
       "      <td>-769.076518</td>\n",
       "      <td>-243.909948</td>\n",
       "      <td>-270.581913</td>\n",
       "      <td>0.599720</td>\n",
       "      <td>1.724782</td>\n",
       "      <td>2.678034</td>\n",
       "      <td>613.972600</td>\n",
       "      <td>284.952954</td>\n",
       "      <td>221.015193</td>\n",
       "      <td>0.495170</td>\n",
       "      <td>0.570305</td>\n",
       "      <td>0.389646</td>\n",
       "      <td>108.258866</td>\n",
       "      <td>60.514531</td>\n",
       "      <td>46.148326</td>\n",
       "      <td>0.245193</td>\n",
       "      <td>0.325247</td>\n",
       "      <td>0.151824</td>\n",
       "      <td>11719.982095</td>\n",
       "      <td>3662.008463</td>\n",
       "      <td>2129.668017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sum_acc_x   sum_acc_y   sum_acc_z  ...      var_gy_x      var_gy_y     var_gy_z\n",
       "id                                      ...                                         \n",
       "0   558.797337 -131.082711 -222.252919  ...    176.470384    590.513292   638.834979\n",
       "1  -459.948117 -190.354639   -2.534051  ...   6279.700472   9217.015511  5707.098884\n",
       "2    23.901616  -49.441742  375.607013  ...    646.325142  14150.683677   193.775778\n",
       "3  -532.621192  -52.600737  136.413976  ...   1842.887012   1365.558625   559.187841\n",
       "4  -395.410844 -202.240064  121.654507  ...  11719.982095   3662.008463  2129.668017\n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_columns = [agg + '_' + column for agg,column in X_pivot_train.columns]\n",
    "X_pivot_train.columns = X_columns\n",
    "X_pivot_test.columns = X_columns\n",
    "display(X_pivot_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "joint-hampton",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "executionInfo": {
     "elapsed": 604,
     "status": "ok",
     "timestamp": 1613799817015,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "joint-hampton",
    "outputId": "57e21bf2-903d-4b6c-f413-6ea413840beb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sum_acc_x</th>\n",
       "      <th>sum_acc_y</th>\n",
       "      <th>sum_acc_z</th>\n",
       "      <th>sum_gy_x</th>\n",
       "      <th>sum_gy_y</th>\n",
       "      <th>sum_gy_z</th>\n",
       "      <th>mean_acc_x</th>\n",
       "      <th>mean_acc_y</th>\n",
       "      <th>mean_acc_z</th>\n",
       "      <th>mean_gy_x</th>\n",
       "      <th>mean_gy_y</th>\n",
       "      <th>mean_gy_z</th>\n",
       "      <th>median_acc_x</th>\n",
       "      <th>median_acc_y</th>\n",
       "      <th>median_acc_z</th>\n",
       "      <th>median_gy_x</th>\n",
       "      <th>median_gy_y</th>\n",
       "      <th>median_gy_z</th>\n",
       "      <th>min_acc_x</th>\n",
       "      <th>min_acc_y</th>\n",
       "      <th>min_acc_z</th>\n",
       "      <th>min_gy_x</th>\n",
       "      <th>min_gy_y</th>\n",
       "      <th>min_gy_z</th>\n",
       "      <th>max_acc_x</th>\n",
       "      <th>max_acc_y</th>\n",
       "      <th>max_acc_z</th>\n",
       "      <th>max_gy_x</th>\n",
       "      <th>max_gy_y</th>\n",
       "      <th>max_gy_z</th>\n",
       "      <th>std_acc_x</th>\n",
       "      <th>std_acc_y</th>\n",
       "      <th>std_acc_z</th>\n",
       "      <th>std_gy_x</th>\n",
       "      <th>std_gy_y</th>\n",
       "      <th>std_gy_z</th>\n",
       "      <th>var_acc_x</th>\n",
       "      <th>var_acc_y</th>\n",
       "      <th>var_acc_z</th>\n",
       "      <th>var_gy_x</th>\n",
       "      <th>var_gy_y</th>\n",
       "      <th>var_gy_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>558.797337</td>\n",
       "      <td>-131.082711</td>\n",
       "      <td>-222.252919</td>\n",
       "      <td>-1119.161589</td>\n",
       "      <td>-2015.703683</td>\n",
       "      <td>709.264425</td>\n",
       "      <td>0.931329</td>\n",
       "      <td>-0.218471</td>\n",
       "      <td>-0.370422</td>\n",
       "      <td>-1.865269</td>\n",
       "      <td>-3.359506</td>\n",
       "      <td>1.182107</td>\n",
       "      <td>0.956149</td>\n",
       "      <td>-0.240638</td>\n",
       "      <td>-0.346749</td>\n",
       "      <td>-1.273569</td>\n",
       "      <td>-2.362230</td>\n",
       "      <td>1.913286</td>\n",
       "      <td>0.591940</td>\n",
       "      <td>-0.624113</td>\n",
       "      <td>-0.786336</td>\n",
       "      <td>-46.254836</td>\n",
       "      <td>-85.887677</td>\n",
       "      <td>-79.930029</td>\n",
       "      <td>1.344268</td>\n",
       "      <td>0.176871</td>\n",
       "      <td>-0.054876</td>\n",
       "      <td>31.644123</td>\n",
       "      <td>69.847244</td>\n",
       "      <td>55.953827</td>\n",
       "      <td>0.191479</td>\n",
       "      <td>0.177131</td>\n",
       "      <td>0.135131</td>\n",
       "      <td>13.284216</td>\n",
       "      <td>24.300479</td>\n",
       "      <td>25.275185</td>\n",
       "      <td>0.036664</td>\n",
       "      <td>0.031375</td>\n",
       "      <td>0.018260</td>\n",
       "      <td>176.470384</td>\n",
       "      <td>590.513292</td>\n",
       "      <td>638.834979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-459.948117</td>\n",
       "      <td>-190.354639</td>\n",
       "      <td>-2.534051</td>\n",
       "      <td>6642.960123</td>\n",
       "      <td>1044.284884</td>\n",
       "      <td>835.976169</td>\n",
       "      <td>-0.766580</td>\n",
       "      <td>-0.317258</td>\n",
       "      <td>-0.004223</td>\n",
       "      <td>11.071600</td>\n",
       "      <td>1.740475</td>\n",
       "      <td>1.393294</td>\n",
       "      <td>-0.805767</td>\n",
       "      <td>-0.228905</td>\n",
       "      <td>-0.034583</td>\n",
       "      <td>3.810650</td>\n",
       "      <td>8.043707</td>\n",
       "      <td>-0.655819</td>\n",
       "      <td>-2.156208</td>\n",
       "      <td>-1.295598</td>\n",
       "      <td>-1.019531</td>\n",
       "      <td>-325.328531</td>\n",
       "      <td>-315.096003</td>\n",
       "      <td>-270.980823</td>\n",
       "      <td>1.234020</td>\n",
       "      <td>0.700065</td>\n",
       "      <td>0.888661</td>\n",
       "      <td>286.624363</td>\n",
       "      <td>389.608060</td>\n",
       "      <td>340.170199</td>\n",
       "      <td>0.495528</td>\n",
       "      <td>0.336415</td>\n",
       "      <td>0.499395</td>\n",
       "      <td>79.244561</td>\n",
       "      <td>96.005289</td>\n",
       "      <td>75.545343</td>\n",
       "      <td>0.245548</td>\n",
       "      <td>0.113175</td>\n",
       "      <td>0.249396</td>\n",
       "      <td>6279.700472</td>\n",
       "      <td>9217.015511</td>\n",
       "      <td>5707.098884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23.901616</td>\n",
       "      <td>-49.441742</td>\n",
       "      <td>375.607013</td>\n",
       "      <td>-5083.770868</td>\n",
       "      <td>358.725917</td>\n",
       "      <td>1831.974458</td>\n",
       "      <td>0.039836</td>\n",
       "      <td>-0.082403</td>\n",
       "      <td>0.626012</td>\n",
       "      <td>-8.472951</td>\n",
       "      <td>0.597877</td>\n",
       "      <td>3.053291</td>\n",
       "      <td>0.140667</td>\n",
       "      <td>-0.062598</td>\n",
       "      <td>0.634781</td>\n",
       "      <td>-8.112557</td>\n",
       "      <td>19.306132</td>\n",
       "      <td>3.568888</td>\n",
       "      <td>-1.142847</td>\n",
       "      <td>-0.690990</td>\n",
       "      <td>0.073846</td>\n",
       "      <td>-164.779067</td>\n",
       "      <td>-249.953944</td>\n",
       "      <td>-44.192071</td>\n",
       "      <td>1.219836</td>\n",
       "      <td>0.650645</td>\n",
       "      <td>1.332992</td>\n",
       "      <td>73.525082</td>\n",
       "      <td>297.320834</td>\n",
       "      <td>55.642836</td>\n",
       "      <td>0.711972</td>\n",
       "      <td>0.147127</td>\n",
       "      <td>0.248807</td>\n",
       "      <td>25.422926</td>\n",
       "      <td>118.956646</td>\n",
       "      <td>13.920337</td>\n",
       "      <td>0.506904</td>\n",
       "      <td>0.021646</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>646.325142</td>\n",
       "      <td>14150.683677</td>\n",
       "      <td>193.775778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-532.621192</td>\n",
       "      <td>-52.600737</td>\n",
       "      <td>136.413976</td>\n",
       "      <td>10646.500409</td>\n",
       "      <td>2880.558352</td>\n",
       "      <td>-3521.938833</td>\n",
       "      <td>-0.887702</td>\n",
       "      <td>-0.087668</td>\n",
       "      <td>0.227357</td>\n",
       "      <td>17.744167</td>\n",
       "      <td>4.800931</td>\n",
       "      <td>-5.869898</td>\n",
       "      <td>-0.880343</td>\n",
       "      <td>-0.054577</td>\n",
       "      <td>0.231537</td>\n",
       "      <td>8.229938</td>\n",
       "      <td>1.783260</td>\n",
       "      <td>-3.853078</td>\n",
       "      <td>-1.417751</td>\n",
       "      <td>-0.540827</td>\n",
       "      <td>-0.257124</td>\n",
       "      <td>-69.419166</td>\n",
       "      <td>-82.537304</td>\n",
       "      <td>-85.600536</td>\n",
       "      <td>-0.622250</td>\n",
       "      <td>0.283721</td>\n",
       "      <td>0.598814</td>\n",
       "      <td>192.765368</td>\n",
       "      <td>159.083788</td>\n",
       "      <td>56.456908</td>\n",
       "      <td>0.130899</td>\n",
       "      <td>0.194008</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>42.928860</td>\n",
       "      <td>36.953466</td>\n",
       "      <td>23.647153</td>\n",
       "      <td>0.017134</td>\n",
       "      <td>0.037639</td>\n",
       "      <td>0.042387</td>\n",
       "      <td>1842.887012</td>\n",
       "      <td>1365.558625</td>\n",
       "      <td>559.187841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-395.410844</td>\n",
       "      <td>-202.240064</td>\n",
       "      <td>121.654507</td>\n",
       "      <td>-2891.782899</td>\n",
       "      <td>5791.027696</td>\n",
       "      <td>2672.029417</td>\n",
       "      <td>-0.659018</td>\n",
       "      <td>-0.337067</td>\n",
       "      <td>0.202758</td>\n",
       "      <td>-4.819638</td>\n",
       "      <td>9.651713</td>\n",
       "      <td>4.453382</td>\n",
       "      <td>-0.941146</td>\n",
       "      <td>-0.168467</td>\n",
       "      <td>0.293556</td>\n",
       "      <td>-1.292194</td>\n",
       "      <td>0.977772</td>\n",
       "      <td>-0.750283</td>\n",
       "      <td>-2.429109</td>\n",
       "      <td>-2.055076</td>\n",
       "      <td>-1.250483</td>\n",
       "      <td>-769.076518</td>\n",
       "      <td>-243.909948</td>\n",
       "      <td>-270.581913</td>\n",
       "      <td>0.599720</td>\n",
       "      <td>1.724782</td>\n",
       "      <td>2.678034</td>\n",
       "      <td>613.972600</td>\n",
       "      <td>284.952954</td>\n",
       "      <td>221.015193</td>\n",
       "      <td>0.495170</td>\n",
       "      <td>0.570305</td>\n",
       "      <td>0.389646</td>\n",
       "      <td>108.258866</td>\n",
       "      <td>60.514531</td>\n",
       "      <td>46.148326</td>\n",
       "      <td>0.245193</td>\n",
       "      <td>0.325247</td>\n",
       "      <td>0.151824</td>\n",
       "      <td>11719.982095</td>\n",
       "      <td>3662.008463</td>\n",
       "      <td>2129.668017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   sum_acc_x   sum_acc_y  ...      var_gy_x      var_gy_y     var_gy_z\n",
       "0   0  558.797337 -131.082711  ...    176.470384    590.513292   638.834979\n",
       "1   1 -459.948117 -190.354639  ...   6279.700472   9217.015511  5707.098884\n",
       "2   2   23.901616  -49.441742  ...    646.325142  14150.683677   193.775778\n",
       "3   3 -532.621192  -52.600737  ...   1842.887012   1365.558625   559.187841\n",
       "4   4 -395.410844 -202.240064  ...  11719.982095   3662.008463  2129.668017\n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sum_acc_x</th>\n",
       "      <th>sum_acc_y</th>\n",
       "      <th>sum_acc_z</th>\n",
       "      <th>sum_gy_x</th>\n",
       "      <th>sum_gy_y</th>\n",
       "      <th>sum_gy_z</th>\n",
       "      <th>mean_acc_x</th>\n",
       "      <th>mean_acc_y</th>\n",
       "      <th>mean_acc_z</th>\n",
       "      <th>mean_gy_x</th>\n",
       "      <th>mean_gy_y</th>\n",
       "      <th>mean_gy_z</th>\n",
       "      <th>median_acc_x</th>\n",
       "      <th>median_acc_y</th>\n",
       "      <th>median_acc_z</th>\n",
       "      <th>median_gy_x</th>\n",
       "      <th>median_gy_y</th>\n",
       "      <th>median_gy_z</th>\n",
       "      <th>min_acc_x</th>\n",
       "      <th>min_acc_y</th>\n",
       "      <th>min_acc_z</th>\n",
       "      <th>min_gy_x</th>\n",
       "      <th>min_gy_y</th>\n",
       "      <th>min_gy_z</th>\n",
       "      <th>max_acc_x</th>\n",
       "      <th>max_acc_y</th>\n",
       "      <th>max_acc_z</th>\n",
       "      <th>max_gy_x</th>\n",
       "      <th>max_gy_y</th>\n",
       "      <th>max_gy_z</th>\n",
       "      <th>std_acc_x</th>\n",
       "      <th>std_acc_y</th>\n",
       "      <th>std_acc_z</th>\n",
       "      <th>std_gy_x</th>\n",
       "      <th>std_gy_y</th>\n",
       "      <th>std_gy_z</th>\n",
       "      <th>var_acc_x</th>\n",
       "      <th>var_acc_y</th>\n",
       "      <th>var_acc_z</th>\n",
       "      <th>var_gy_x</th>\n",
       "      <th>var_gy_y</th>\n",
       "      <th>var_gy_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3125</td>\n",
       "      <td>-611.238360</td>\n",
       "      <td>-11.744605</td>\n",
       "      <td>-139.355669</td>\n",
       "      <td>-1911.076959</td>\n",
       "      <td>1639.123438</td>\n",
       "      <td>-1200.410049</td>\n",
       "      <td>-1.018731</td>\n",
       "      <td>-0.019574</td>\n",
       "      <td>-0.232259</td>\n",
       "      <td>-3.185128</td>\n",
       "      <td>2.731872</td>\n",
       "      <td>-2.000683</td>\n",
       "      <td>-1.064222</td>\n",
       "      <td>-0.005735</td>\n",
       "      <td>-0.268442</td>\n",
       "      <td>-3.770150</td>\n",
       "      <td>0.108956</td>\n",
       "      <td>-1.607847</td>\n",
       "      <td>-1.564000</td>\n",
       "      <td>-0.470937</td>\n",
       "      <td>-0.573836</td>\n",
       "      <td>-50.429364</td>\n",
       "      <td>-81.607713</td>\n",
       "      <td>-35.446915</td>\n",
       "      <td>-0.275446</td>\n",
       "      <td>0.228040</td>\n",
       "      <td>0.286182</td>\n",
       "      <td>56.953059</td>\n",
       "      <td>96.185341</td>\n",
       "      <td>49.981455</td>\n",
       "      <td>0.236232</td>\n",
       "      <td>0.091641</td>\n",
       "      <td>0.174672</td>\n",
       "      <td>12.897967</td>\n",
       "      <td>31.993022</td>\n",
       "      <td>12.251648</td>\n",
       "      <td>0.055806</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.030510</td>\n",
       "      <td>166.357553</td>\n",
       "      <td>1023.553453</td>\n",
       "      <td>150.102867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3126</td>\n",
       "      <td>-313.705824</td>\n",
       "      <td>367.296809</td>\n",
       "      <td>-42.655405</td>\n",
       "      <td>-10644.915365</td>\n",
       "      <td>4184.863263</td>\n",
       "      <td>-2162.747150</td>\n",
       "      <td>-0.522843</td>\n",
       "      <td>0.612161</td>\n",
       "      <td>-0.071092</td>\n",
       "      <td>-17.741526</td>\n",
       "      <td>6.974772</td>\n",
       "      <td>-3.604579</td>\n",
       "      <td>-0.677411</td>\n",
       "      <td>0.606215</td>\n",
       "      <td>-0.026089</td>\n",
       "      <td>-14.305258</td>\n",
       "      <td>-0.974696</td>\n",
       "      <td>-10.833508</td>\n",
       "      <td>-1.929033</td>\n",
       "      <td>-0.200678</td>\n",
       "      <td>-1.212052</td>\n",
       "      <td>-273.572486</td>\n",
       "      <td>-97.100707</td>\n",
       "      <td>-147.597574</td>\n",
       "      <td>0.627571</td>\n",
       "      <td>1.708743</td>\n",
       "      <td>0.671876</td>\n",
       "      <td>132.830402</td>\n",
       "      <td>241.240196</td>\n",
       "      <td>169.417650</td>\n",
       "      <td>0.539688</td>\n",
       "      <td>0.333015</td>\n",
       "      <td>0.383800</td>\n",
       "      <td>51.625096</td>\n",
       "      <td>45.706311</td>\n",
       "      <td>61.604867</td>\n",
       "      <td>0.291264</td>\n",
       "      <td>0.110899</td>\n",
       "      <td>0.147302</td>\n",
       "      <td>2665.150566</td>\n",
       "      <td>2089.066820</td>\n",
       "      <td>3795.159662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3127</td>\n",
       "      <td>304.167948</td>\n",
       "      <td>542.291164</td>\n",
       "      <td>-84.658968</td>\n",
       "      <td>-1307.846921</td>\n",
       "      <td>-1350.871152</td>\n",
       "      <td>-235.904841</td>\n",
       "      <td>0.506947</td>\n",
       "      <td>0.903819</td>\n",
       "      <td>-0.141098</td>\n",
       "      <td>-2.179745</td>\n",
       "      <td>-2.251452</td>\n",
       "      <td>-0.393175</td>\n",
       "      <td>0.497370</td>\n",
       "      <td>0.931239</td>\n",
       "      <td>-0.156647</td>\n",
       "      <td>0.476247</td>\n",
       "      <td>-2.319172</td>\n",
       "      <td>-3.087735</td>\n",
       "      <td>-0.792916</td>\n",
       "      <td>0.219008</td>\n",
       "      <td>-0.484614</td>\n",
       "      <td>-99.799971</td>\n",
       "      <td>-98.420987</td>\n",
       "      <td>-154.477074</td>\n",
       "      <td>2.972063</td>\n",
       "      <td>1.941820</td>\n",
       "      <td>0.644154</td>\n",
       "      <td>160.426058</td>\n",
       "      <td>74.530763</td>\n",
       "      <td>97.211730</td>\n",
       "      <td>0.219934</td>\n",
       "      <td>0.191485</td>\n",
       "      <td>0.152077</td>\n",
       "      <td>22.770845</td>\n",
       "      <td>13.467885</td>\n",
       "      <td>23.041463</td>\n",
       "      <td>0.048371</td>\n",
       "      <td>0.036666</td>\n",
       "      <td>0.023128</td>\n",
       "      <td>518.511372</td>\n",
       "      <td>181.383940</td>\n",
       "      <td>530.909012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3128</td>\n",
       "      <td>-346.561617</td>\n",
       "      <td>-366.333946</td>\n",
       "      <td>18.891749</td>\n",
       "      <td>485.147442</td>\n",
       "      <td>-1790.981310</td>\n",
       "      <td>-14.590798</td>\n",
       "      <td>-0.577603</td>\n",
       "      <td>-0.610557</td>\n",
       "      <td>0.031486</td>\n",
       "      <td>0.808579</td>\n",
       "      <td>-2.984969</td>\n",
       "      <td>-0.024318</td>\n",
       "      <td>-0.880541</td>\n",
       "      <td>-0.507927</td>\n",
       "      <td>-0.092860</td>\n",
       "      <td>1.457625</td>\n",
       "      <td>-0.269600</td>\n",
       "      <td>-0.404583</td>\n",
       "      <td>-1.045889</td>\n",
       "      <td>-1.294482</td>\n",
       "      <td>-0.469924</td>\n",
       "      <td>-229.072919</td>\n",
       "      <td>-168.031080</td>\n",
       "      <td>-117.297766</td>\n",
       "      <td>0.337281</td>\n",
       "      <td>-0.258476</td>\n",
       "      <td>0.702574</td>\n",
       "      <td>119.527887</td>\n",
       "      <td>118.268797</td>\n",
       "      <td>167.860762</td>\n",
       "      <td>0.431713</td>\n",
       "      <td>0.233601</td>\n",
       "      <td>0.326569</td>\n",
       "      <td>42.818157</td>\n",
       "      <td>45.069932</td>\n",
       "      <td>37.967372</td>\n",
       "      <td>0.186376</td>\n",
       "      <td>0.054569</td>\n",
       "      <td>0.106647</td>\n",
       "      <td>1833.394532</td>\n",
       "      <td>2031.298793</td>\n",
       "      <td>1441.521366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3129</td>\n",
       "      <td>-443.184021</td>\n",
       "      <td>109.521180</td>\n",
       "      <td>240.781103</td>\n",
       "      <td>-858.922755</td>\n",
       "      <td>865.419381</td>\n",
       "      <td>3447.298941</td>\n",
       "      <td>-0.738640</td>\n",
       "      <td>0.182535</td>\n",
       "      <td>0.401302</td>\n",
       "      <td>-1.431538</td>\n",
       "      <td>1.442366</td>\n",
       "      <td>5.745498</td>\n",
       "      <td>-0.703842</td>\n",
       "      <td>0.122280</td>\n",
       "      <td>0.432678</td>\n",
       "      <td>-3.066063</td>\n",
       "      <td>1.631638</td>\n",
       "      <td>1.866352</td>\n",
       "      <td>-2.153047</td>\n",
       "      <td>-0.860883</td>\n",
       "      <td>-0.631258</td>\n",
       "      <td>-345.447240</td>\n",
       "      <td>-223.475411</td>\n",
       "      <td>-125.598600</td>\n",
       "      <td>0.015642</td>\n",
       "      <td>1.562602</td>\n",
       "      <td>1.037876</td>\n",
       "      <td>366.167357</td>\n",
       "      <td>226.728939</td>\n",
       "      <td>138.130133</td>\n",
       "      <td>0.305797</td>\n",
       "      <td>0.314294</td>\n",
       "      <td>0.261848</td>\n",
       "      <td>92.301963</td>\n",
       "      <td>67.911174</td>\n",
       "      <td>43.353007</td>\n",
       "      <td>0.093512</td>\n",
       "      <td>0.098781</td>\n",
       "      <td>0.068565</td>\n",
       "      <td>8519.652350</td>\n",
       "      <td>4611.927587</td>\n",
       "      <td>1879.483194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   sum_acc_x   sum_acc_y  ...     var_gy_x     var_gy_y     var_gy_z\n",
       "0  3125 -611.238360  -11.744605  ...   166.357553  1023.553453   150.102867\n",
       "1  3126 -313.705824  367.296809  ...  2665.150566  2089.066820  3795.159662\n",
       "2  3127  304.167948  542.291164  ...   518.511372   181.383940   530.909012\n",
       "3  3128 -346.561617 -366.333946  ...  1833.394532  2031.298793  1441.521366\n",
       "4  3129 -443.184021  109.521180  ...  8519.652350  4611.927587  1879.483194\n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_pivot_train = X_pivot_train.reset_index()\n",
    "X_pivot_test = X_pivot_test.reset_index()\n",
    "\n",
    "display(X_pivot_train.head())\n",
    "display(X_pivot_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ranking-civilian",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1613799818203,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "ranking-civilian",
    "outputId": "cf2a26ee-9f31-461d-ca84-4f515106f45f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3125, 43)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pivot_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d2AnJdPiLt",
   "metadata": {
    "id": "c6d2AnJdPiLt"
   },
   "source": [
    "### 학습에 사용할 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "gentle-doctrine",
   "metadata": {
    "executionInfo": {
     "elapsed": 772,
     "status": "ok",
     "timestamp": 1613799818485,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "gentle-doctrine"
   },
   "outputs": [],
   "source": [
    "ftr = X_pivot_train\n",
    "target = y_train['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GKF7A8qb-pUp",
   "metadata": {
    "id": "GKF7A8qb-pUp"
   },
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "informed-pizza",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19611,
     "status": "ok",
     "timestamp": 1613799837667,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "informed-pizza",
    "outputId": "e9fb144e-4525-4411-adaf-07a1970157ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 2.54967\tvalid_0's multi_logloss: 2.54967\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\tvalid_0's multi_logloss: 2.44754\tvalid_0's multi_logloss: 2.44754\n",
      "[3]\tvalid_0's multi_logloss: 2.36224\tvalid_0's multi_logloss: 2.36224\n",
      "[4]\tvalid_0's multi_logloss: 2.28827\tvalid_0's multi_logloss: 2.28827\n",
      "[5]\tvalid_0's multi_logloss: 2.22081\tvalid_0's multi_logloss: 2.22081\n",
      "[6]\tvalid_0's multi_logloss: 2.16124\tvalid_0's multi_logloss: 2.16124\n",
      "[7]\tvalid_0's multi_logloss: 2.10861\tvalid_0's multi_logloss: 2.10861\n",
      "[8]\tvalid_0's multi_logloss: 2.0579\tvalid_0's multi_logloss: 2.0579\n",
      "[9]\tvalid_0's multi_logloss: 2.00773\tvalid_0's multi_logloss: 2.00773\n",
      "[10]\tvalid_0's multi_logloss: 1.96496\tvalid_0's multi_logloss: 1.96496\n",
      "[11]\tvalid_0's multi_logloss: 1.92285\tvalid_0's multi_logloss: 1.92285\n",
      "[12]\tvalid_0's multi_logloss: 1.88298\tvalid_0's multi_logloss: 1.88298\n",
      "[13]\tvalid_0's multi_logloss: 1.84782\tvalid_0's multi_logloss: 1.84782\n",
      "[14]\tvalid_0's multi_logloss: 1.81528\tvalid_0's multi_logloss: 1.81528\n",
      "[15]\tvalid_0's multi_logloss: 1.7849\tvalid_0's multi_logloss: 1.7849\n",
      "[16]\tvalid_0's multi_logloss: 1.74964\tvalid_0's multi_logloss: 1.74964\n",
      "[17]\tvalid_0's multi_logloss: 1.72307\tvalid_0's multi_logloss: 1.72307\n",
      "[18]\tvalid_0's multi_logloss: 1.69399\tvalid_0's multi_logloss: 1.69399\n",
      "[19]\tvalid_0's multi_logloss: 1.66657\tvalid_0's multi_logloss: 1.66657\n",
      "[20]\tvalid_0's multi_logloss: 1.6378\tvalid_0's multi_logloss: 1.6378\n",
      "[21]\tvalid_0's multi_logloss: 1.61022\tvalid_0's multi_logloss: 1.61022\n",
      "[22]\tvalid_0's multi_logloss: 1.58632\tvalid_0's multi_logloss: 1.58632\n",
      "[23]\tvalid_0's multi_logloss: 1.56451\tvalid_0's multi_logloss: 1.56451\n",
      "[24]\tvalid_0's multi_logloss: 1.54248\tvalid_0's multi_logloss: 1.54248\n",
      "[25]\tvalid_0's multi_logloss: 1.5221\tvalid_0's multi_logloss: 1.5221\n",
      "[26]\tvalid_0's multi_logloss: 1.50271\tvalid_0's multi_logloss: 1.50271\n",
      "[27]\tvalid_0's multi_logloss: 1.48135\tvalid_0's multi_logloss: 1.48135\n",
      "[28]\tvalid_0's multi_logloss: 1.46254\tvalid_0's multi_logloss: 1.46254\n",
      "[29]\tvalid_0's multi_logloss: 1.44014\tvalid_0's multi_logloss: 1.44014\n",
      "[30]\tvalid_0's multi_logloss: 1.42699\tvalid_0's multi_logloss: 1.42699\n",
      "[31]\tvalid_0's multi_logloss: 1.40903\tvalid_0's multi_logloss: 1.40903\n",
      "[32]\tvalid_0's multi_logloss: 1.39176\tvalid_0's multi_logloss: 1.39176\n",
      "[33]\tvalid_0's multi_logloss: 1.37603\tvalid_0's multi_logloss: 1.37603\n",
      "[34]\tvalid_0's multi_logloss: 1.36271\tvalid_0's multi_logloss: 1.36271\n",
      "[35]\tvalid_0's multi_logloss: 1.34856\tvalid_0's multi_logloss: 1.34856\n",
      "[36]\tvalid_0's multi_logloss: 1.33284\tvalid_0's multi_logloss: 1.33284\n",
      "[37]\tvalid_0's multi_logloss: 1.31976\tvalid_0's multi_logloss: 1.31976\n",
      "[38]\tvalid_0's multi_logloss: 1.30735\tvalid_0's multi_logloss: 1.30735\n",
      "[39]\tvalid_0's multi_logloss: 1.29583\tvalid_0's multi_logloss: 1.29583\n",
      "[40]\tvalid_0's multi_logloss: 1.28215\tvalid_0's multi_logloss: 1.28215\n",
      "[41]\tvalid_0's multi_logloss: 1.27067\tvalid_0's multi_logloss: 1.27067\n",
      "[42]\tvalid_0's multi_logloss: 1.25805\tvalid_0's multi_logloss: 1.25805\n",
      "[43]\tvalid_0's multi_logloss: 1.24676\tvalid_0's multi_logloss: 1.24676\n",
      "[44]\tvalid_0's multi_logloss: 1.23453\tvalid_0's multi_logloss: 1.23453\n",
      "[45]\tvalid_0's multi_logloss: 1.22391\tvalid_0's multi_logloss: 1.22391\n",
      "[46]\tvalid_0's multi_logloss: 1.21486\tvalid_0's multi_logloss: 1.21486\n",
      "[47]\tvalid_0's multi_logloss: 1.20366\tvalid_0's multi_logloss: 1.20366\n",
      "[48]\tvalid_0's multi_logloss: 1.19522\tvalid_0's multi_logloss: 1.19522\n",
      "[49]\tvalid_0's multi_logloss: 1.18602\tvalid_0's multi_logloss: 1.18602\n",
      "[50]\tvalid_0's multi_logloss: 1.17581\tvalid_0's multi_logloss: 1.17581\n",
      "[51]\tvalid_0's multi_logloss: 1.16673\tvalid_0's multi_logloss: 1.16673\n",
      "[52]\tvalid_0's multi_logloss: 1.15784\tvalid_0's multi_logloss: 1.15784\n",
      "[53]\tvalid_0's multi_logloss: 1.15111\tvalid_0's multi_logloss: 1.15111\n",
      "[54]\tvalid_0's multi_logloss: 1.14383\tvalid_0's multi_logloss: 1.14383\n",
      "[55]\tvalid_0's multi_logloss: 1.13564\tvalid_0's multi_logloss: 1.13564\n",
      "[56]\tvalid_0's multi_logloss: 1.12888\tvalid_0's multi_logloss: 1.12888\n",
      "[57]\tvalid_0's multi_logloss: 1.12103\tvalid_0's multi_logloss: 1.12103\n",
      "[58]\tvalid_0's multi_logloss: 1.11262\tvalid_0's multi_logloss: 1.11262\n",
      "[59]\tvalid_0's multi_logloss: 1.10572\tvalid_0's multi_logloss: 1.10572\n",
      "[60]\tvalid_0's multi_logloss: 1.1007\tvalid_0's multi_logloss: 1.1007\n",
      "[61]\tvalid_0's multi_logloss: 1.09455\tvalid_0's multi_logloss: 1.09455\n",
      "[62]\tvalid_0's multi_logloss: 1.08812\tvalid_0's multi_logloss: 1.08812\n",
      "[63]\tvalid_0's multi_logloss: 1.08245\tvalid_0's multi_logloss: 1.08245\n",
      "[64]\tvalid_0's multi_logloss: 1.07756\tvalid_0's multi_logloss: 1.07756\n",
      "[65]\tvalid_0's multi_logloss: 1.0729\tvalid_0's multi_logloss: 1.0729\n",
      "[66]\tvalid_0's multi_logloss: 1.06775\tvalid_0's multi_logloss: 1.06775\n",
      "[67]\tvalid_0's multi_logloss: 1.06198\tvalid_0's multi_logloss: 1.06198\n",
      "[68]\tvalid_0's multi_logloss: 1.05822\tvalid_0's multi_logloss: 1.05822\n",
      "[69]\tvalid_0's multi_logloss: 1.05378\tvalid_0's multi_logloss: 1.05378\n",
      "[70]\tvalid_0's multi_logloss: 1.04827\tvalid_0's multi_logloss: 1.04827\n",
      "[71]\tvalid_0's multi_logloss: 1.04262\tvalid_0's multi_logloss: 1.04262\n",
      "[72]\tvalid_0's multi_logloss: 1.03976\tvalid_0's multi_logloss: 1.03976\n",
      "[73]\tvalid_0's multi_logloss: 1.03594\tvalid_0's multi_logloss: 1.03594\n",
      "[74]\tvalid_0's multi_logloss: 1.03051\tvalid_0's multi_logloss: 1.03051\n",
      "[75]\tvalid_0's multi_logloss: 1.02632\tvalid_0's multi_logloss: 1.02632\n",
      "[76]\tvalid_0's multi_logloss: 1.0233\tvalid_0's multi_logloss: 1.0233\n",
      "[77]\tvalid_0's multi_logloss: 1.01978\tvalid_0's multi_logloss: 1.01978\n",
      "[78]\tvalid_0's multi_logloss: 1.01682\tvalid_0's multi_logloss: 1.01682\n",
      "[79]\tvalid_0's multi_logloss: 1.01471\tvalid_0's multi_logloss: 1.01471\n",
      "[80]\tvalid_0's multi_logloss: 1.01193\tvalid_0's multi_logloss: 1.01193\n",
      "[81]\tvalid_0's multi_logloss: 1.0098\tvalid_0's multi_logloss: 1.0098\n",
      "[82]\tvalid_0's multi_logloss: 1.0081\tvalid_0's multi_logloss: 1.0081\n",
      "[83]\tvalid_0's multi_logloss: 1.00474\tvalid_0's multi_logloss: 1.00474\n",
      "[84]\tvalid_0's multi_logloss: 1.00135\tvalid_0's multi_logloss: 1.00135\n",
      "[85]\tvalid_0's multi_logloss: 0.999704\tvalid_0's multi_logloss: 0.999704\n",
      "[86]\tvalid_0's multi_logloss: 0.997162\tvalid_0's multi_logloss: 0.997162\n",
      "[87]\tvalid_0's multi_logloss: 0.995046\tvalid_0's multi_logloss: 0.995046\n",
      "[88]\tvalid_0's multi_logloss: 0.994163\tvalid_0's multi_logloss: 0.994163\n",
      "[89]\tvalid_0's multi_logloss: 0.99225\tvalid_0's multi_logloss: 0.99225\n",
      "[90]\tvalid_0's multi_logloss: 0.989786\tvalid_0's multi_logloss: 0.989786\n",
      "[91]\tvalid_0's multi_logloss: 0.987736\tvalid_0's multi_logloss: 0.987736\n",
      "[92]\tvalid_0's multi_logloss: 0.987379\tvalid_0's multi_logloss: 0.987379\n",
      "[93]\tvalid_0's multi_logloss: 0.984856\tvalid_0's multi_logloss: 0.984856\n",
      "[94]\tvalid_0's multi_logloss: 0.984519\tvalid_0's multi_logloss: 0.984519\n",
      "[95]\tvalid_0's multi_logloss: 0.982241\tvalid_0's multi_logloss: 0.982241\n",
      "[96]\tvalid_0's multi_logloss: 0.980415\tvalid_0's multi_logloss: 0.980415\n",
      "[97]\tvalid_0's multi_logloss: 0.9793\tvalid_0's multi_logloss: 0.9793\n",
      "[98]\tvalid_0's multi_logloss: 0.977519\tvalid_0's multi_logloss: 0.977519\n",
      "[99]\tvalid_0's multi_logloss: 0.976512\tvalid_0's multi_logloss: 0.976512\n",
      "[100]\tvalid_0's multi_logloss: 0.975002\tvalid_0's multi_logloss: 0.975002\n",
      "[101]\tvalid_0's multi_logloss: 0.974606\tvalid_0's multi_logloss: 0.974606\n",
      "[102]\tvalid_0's multi_logloss: 0.973015\tvalid_0's multi_logloss: 0.973015\n",
      "[103]\tvalid_0's multi_logloss: 0.972921\tvalid_0's multi_logloss: 0.972921\n",
      "[104]\tvalid_0's multi_logloss: 0.971878\tvalid_0's multi_logloss: 0.971878\n",
      "[105]\tvalid_0's multi_logloss: 0.970414\tvalid_0's multi_logloss: 0.970414\n",
      "[106]\tvalid_0's multi_logloss: 0.969372\tvalid_0's multi_logloss: 0.969372\n",
      "[107]\tvalid_0's multi_logloss: 0.968371\tvalid_0's multi_logloss: 0.968371\n",
      "[108]\tvalid_0's multi_logloss: 0.967937\tvalid_0's multi_logloss: 0.967937\n",
      "[109]\tvalid_0's multi_logloss: 0.966931\tvalid_0's multi_logloss: 0.966931\n",
      "[110]\tvalid_0's multi_logloss: 0.965549\tvalid_0's multi_logloss: 0.965549\n",
      "[111]\tvalid_0's multi_logloss: 0.965444\tvalid_0's multi_logloss: 0.965444\n",
      "[112]\tvalid_0's multi_logloss: 0.965779\tvalid_0's multi_logloss: 0.965779\n",
      "[113]\tvalid_0's multi_logloss: 0.965434\tvalid_0's multi_logloss: 0.965434\n",
      "[114]\tvalid_0's multi_logloss: 0.966266\tvalid_0's multi_logloss: 0.966266\n",
      "[115]\tvalid_0's multi_logloss: 0.967185\tvalid_0's multi_logloss: 0.967185\n",
      "[116]\tvalid_0's multi_logloss: 0.9688\tvalid_0's multi_logloss: 0.9688\n",
      "[117]\tvalid_0's multi_logloss: 0.967503\tvalid_0's multi_logloss: 0.967503\n",
      "[118]\tvalid_0's multi_logloss: 0.967405\tvalid_0's multi_logloss: 0.967405\n",
      "[119]\tvalid_0's multi_logloss: 0.967307\tvalid_0's multi_logloss: 0.967307\n",
      "[120]\tvalid_0's multi_logloss: 0.967074\tvalid_0's multi_logloss: 0.967074\n",
      "[121]\tvalid_0's multi_logloss: 0.965506\tvalid_0's multi_logloss: 0.965506\n",
      "[122]\tvalid_0's multi_logloss: 0.965944\tvalid_0's multi_logloss: 0.965944\n",
      "[123]\tvalid_0's multi_logloss: 0.965724\tvalid_0's multi_logloss: 0.965724\n",
      "[124]\tvalid_0's multi_logloss: 0.965148\tvalid_0's multi_logloss: 0.965148\n",
      "[125]\tvalid_0's multi_logloss: 0.964324\tvalid_0's multi_logloss: 0.964324\n",
      "[126]\tvalid_0's multi_logloss: 0.964763\tvalid_0's multi_logloss: 0.964763\n",
      "[127]\tvalid_0's multi_logloss: 0.963924\tvalid_0's multi_logloss: 0.963924\n",
      "[128]\tvalid_0's multi_logloss: 0.963473\tvalid_0's multi_logloss: 0.963473\n",
      "[129]\tvalid_0's multi_logloss: 0.964156\tvalid_0's multi_logloss: 0.964156\n",
      "[130]\tvalid_0's multi_logloss: 0.963034\tvalid_0's multi_logloss: 0.963034\n",
      "[131]\tvalid_0's multi_logloss: 0.962912\tvalid_0's multi_logloss: 0.962912\n",
      "[132]\tvalid_0's multi_logloss: 0.963537\tvalid_0's multi_logloss: 0.963537\n",
      "[133]\tvalid_0's multi_logloss: 0.963192\tvalid_0's multi_logloss: 0.963192\n",
      "[134]\tvalid_0's multi_logloss: 0.962893\tvalid_0's multi_logloss: 0.962893\n",
      "[135]\tvalid_0's multi_logloss: 0.963725\tvalid_0's multi_logloss: 0.963725\n",
      "[136]\tvalid_0's multi_logloss: 0.963652\tvalid_0's multi_logloss: 0.963652\n",
      "[137]\tvalid_0's multi_logloss: 0.96313\tvalid_0's multi_logloss: 0.96313\n",
      "[138]\tvalid_0's multi_logloss: 0.964062\tvalid_0's multi_logloss: 0.964062\n",
      "[139]\tvalid_0's multi_logloss: 0.963734\tvalid_0's multi_logloss: 0.963734\n",
      "[140]\tvalid_0's multi_logloss: 0.964793\tvalid_0's multi_logloss: 0.964793\n",
      "[141]\tvalid_0's multi_logloss: 0.965015\tvalid_0's multi_logloss: 0.965015\n",
      "[142]\tvalid_0's multi_logloss: 0.964592\tvalid_0's multi_logloss: 0.964592\n",
      "[143]\tvalid_0's multi_logloss: 0.96443\tvalid_0's multi_logloss: 0.96443\n",
      "[144]\tvalid_0's multi_logloss: 0.966142\tvalid_0's multi_logloss: 0.966142\n",
      "[145]\tvalid_0's multi_logloss: 0.966605\tvalid_0's multi_logloss: 0.966605\n",
      "[146]\tvalid_0's multi_logloss: 0.966669\tvalid_0's multi_logloss: 0.966669\n",
      "[147]\tvalid_0's multi_logloss: 0.967056\tvalid_0's multi_logloss: 0.967056\n",
      "[148]\tvalid_0's multi_logloss: 0.968562\tvalid_0's multi_logloss: 0.968562\n",
      "[149]\tvalid_0's multi_logloss: 0.968473\tvalid_0's multi_logloss: 0.968473\n",
      "[150]\tvalid_0's multi_logloss: 0.968264\tvalid_0's multi_logloss: 0.968264\n",
      "[151]\tvalid_0's multi_logloss: 0.968964\tvalid_0's multi_logloss: 0.968964\n",
      "[152]\tvalid_0's multi_logloss: 0.970481\tvalid_0's multi_logloss: 0.970481\n",
      "[153]\tvalid_0's multi_logloss: 0.971918\tvalid_0's multi_logloss: 0.971918\n",
      "[154]\tvalid_0's multi_logloss: 0.972024\tvalid_0's multi_logloss: 0.972024\n",
      "[155]\tvalid_0's multi_logloss: 0.971248\tvalid_0's multi_logloss: 0.971248\n",
      "[156]\tvalid_0's multi_logloss: 0.972121\tvalid_0's multi_logloss: 0.972121\n",
      "[157]\tvalid_0's multi_logloss: 0.973903\tvalid_0's multi_logloss: 0.973903\n",
      "[158]\tvalid_0's multi_logloss: 0.974328\tvalid_0's multi_logloss: 0.974328\n",
      "[159]\tvalid_0's multi_logloss: 0.975217\tvalid_0's multi_logloss: 0.975217\n",
      "[160]\tvalid_0's multi_logloss: 0.974863\tvalid_0's multi_logloss: 0.974863\n",
      "[161]\tvalid_0's multi_logloss: 0.974595\tvalid_0's multi_logloss: 0.974595\n",
      "[162]\tvalid_0's multi_logloss: 0.974939\tvalid_0's multi_logloss: 0.974939\n",
      "[163]\tvalid_0's multi_logloss: 0.975323\tvalid_0's multi_logloss: 0.975323\n",
      "[164]\tvalid_0's multi_logloss: 0.97587\tvalid_0's multi_logloss: 0.97587\n",
      "[165]\tvalid_0's multi_logloss: 0.975551\tvalid_0's multi_logloss: 0.975551\n",
      "[166]\tvalid_0's multi_logloss: 0.975601\tvalid_0's multi_logloss: 0.975601\n",
      "[167]\tvalid_0's multi_logloss: 0.976523\tvalid_0's multi_logloss: 0.976523\n",
      "[168]\tvalid_0's multi_logloss: 0.977619\tvalid_0's multi_logloss: 0.977619\n",
      "[169]\tvalid_0's multi_logloss: 0.9773\tvalid_0's multi_logloss: 0.9773\n",
      "[170]\tvalid_0's multi_logloss: 0.978554\tvalid_0's multi_logloss: 0.978554\n",
      "[171]\tvalid_0's multi_logloss: 0.979396\tvalid_0's multi_logloss: 0.979396\n",
      "[172]\tvalid_0's multi_logloss: 0.979107\tvalid_0's multi_logloss: 0.979107\n",
      "[173]\tvalid_0's multi_logloss: 0.979147\tvalid_0's multi_logloss: 0.979147\n",
      "[174]\tvalid_0's multi_logloss: 0.980407\tvalid_0's multi_logloss: 0.980407\n",
      "[175]\tvalid_0's multi_logloss: 0.979793\tvalid_0's multi_logloss: 0.979793\n",
      "[176]\tvalid_0's multi_logloss: 0.981223\tvalid_0's multi_logloss: 0.981223\n",
      "[177]\tvalid_0's multi_logloss: 0.980955\tvalid_0's multi_logloss: 0.980955\n",
      "[178]\tvalid_0's multi_logloss: 0.981087\tvalid_0's multi_logloss: 0.981087\n",
      "[179]\tvalid_0's multi_logloss: 0.982114\tvalid_0's multi_logloss: 0.982114\n",
      "[180]\tvalid_0's multi_logloss: 0.982049\tvalid_0's multi_logloss: 0.982049\n",
      "[181]\tvalid_0's multi_logloss: 0.983016\tvalid_0's multi_logloss: 0.983016\n",
      "[182]\tvalid_0's multi_logloss: 0.984608\tvalid_0's multi_logloss: 0.984608\n",
      "[183]\tvalid_0's multi_logloss: 0.985478\tvalid_0's multi_logloss: 0.985478\n",
      "[184]\tvalid_0's multi_logloss: 0.987096\tvalid_0's multi_logloss: 0.987096\n",
      "[185]\tvalid_0's multi_logloss: 0.987124\tvalid_0's multi_logloss: 0.987124\n",
      "[186]\tvalid_0's multi_logloss: 0.9877\tvalid_0's multi_logloss: 0.9877\n",
      "[187]\tvalid_0's multi_logloss: 0.989384\tvalid_0's multi_logloss: 0.989384\n",
      "[188]\tvalid_0's multi_logloss: 0.989807\tvalid_0's multi_logloss: 0.989807\n",
      "[189]\tvalid_0's multi_logloss: 0.991115\tvalid_0's multi_logloss: 0.991115\n",
      "[190]\tvalid_0's multi_logloss: 0.991616\tvalid_0's multi_logloss: 0.991616\n",
      "[191]\tvalid_0's multi_logloss: 0.992475\tvalid_0's multi_logloss: 0.992475\n",
      "[192]\tvalid_0's multi_logloss: 0.99426\tvalid_0's multi_logloss: 0.99426\n",
      "[193]\tvalid_0's multi_logloss: 0.994324\tvalid_0's multi_logloss: 0.994324\n",
      "[194]\tvalid_0's multi_logloss: 0.996424\tvalid_0's multi_logloss: 0.996424\n",
      "[195]\tvalid_0's multi_logloss: 0.997843\tvalid_0's multi_logloss: 0.997843\n",
      "[196]\tvalid_0's multi_logloss: 0.999794\tvalid_0's multi_logloss: 0.999794\n",
      "[197]\tvalid_0's multi_logloss: 0.999898\tvalid_0's multi_logloss: 0.999898\n",
      "[198]\tvalid_0's multi_logloss: 1.00119\tvalid_0's multi_logloss: 1.00119\n",
      "[199]\tvalid_0's multi_logloss: 1.00299\tvalid_0's multi_logloss: 1.00299\n",
      "[200]\tvalid_0's multi_logloss: 1.00396\tvalid_0's multi_logloss: 1.00396\n",
      "[201]\tvalid_0's multi_logloss: 1.00482\tvalid_0's multi_logloss: 1.00482\n",
      "[202]\tvalid_0's multi_logloss: 1.00497\tvalid_0's multi_logloss: 1.00497\n",
      "[203]\tvalid_0's multi_logloss: 1.00574\tvalid_0's multi_logloss: 1.00574\n",
      "[204]\tvalid_0's multi_logloss: 1.00661\tvalid_0's multi_logloss: 1.00661\n",
      "[205]\tvalid_0's multi_logloss: 1.00827\tvalid_0's multi_logloss: 1.00827\n",
      "[206]\tvalid_0's multi_logloss: 1.00948\tvalid_0's multi_logloss: 1.00948\n",
      "[207]\tvalid_0's multi_logloss: 1.01248\tvalid_0's multi_logloss: 1.01248\n",
      "[208]\tvalid_0's multi_logloss: 1.01318\tvalid_0's multi_logloss: 1.01318\n",
      "[209]\tvalid_0's multi_logloss: 1.01565\tvalid_0's multi_logloss: 1.01565\n",
      "[210]\tvalid_0's multi_logloss: 1.01625\tvalid_0's multi_logloss: 1.01625\n",
      "[211]\tvalid_0's multi_logloss: 1.01856\tvalid_0's multi_logloss: 1.01856\n",
      "[212]\tvalid_0's multi_logloss: 1.02094\tvalid_0's multi_logloss: 1.02094\n",
      "[213]\tvalid_0's multi_logloss: 1.02288\tvalid_0's multi_logloss: 1.02288\n",
      "[214]\tvalid_0's multi_logloss: 1.02436\tvalid_0's multi_logloss: 1.02436\n",
      "[215]\tvalid_0's multi_logloss: 1.02575\tvalid_0's multi_logloss: 1.02575\n",
      "[216]\tvalid_0's multi_logloss: 1.02645\tvalid_0's multi_logloss: 1.02645\n",
      "[217]\tvalid_0's multi_logloss: 1.02866\tvalid_0's multi_logloss: 1.02866\n",
      "[218]\tvalid_0's multi_logloss: 1.02973\tvalid_0's multi_logloss: 1.02973\n",
      "[219]\tvalid_0's multi_logloss: 1.03172\tvalid_0's multi_logloss: 1.03172\n",
      "[220]\tvalid_0's multi_logloss: 1.03291\tvalid_0's multi_logloss: 1.03291\n",
      "[221]\tvalid_0's multi_logloss: 1.0343\tvalid_0's multi_logloss: 1.0343\n",
      "[222]\tvalid_0's multi_logloss: 1.03463\tvalid_0's multi_logloss: 1.03463\n",
      "[223]\tvalid_0's multi_logloss: 1.0359\tvalid_0's multi_logloss: 1.0359\n",
      "[224]\tvalid_0's multi_logloss: 1.03796\tvalid_0's multi_logloss: 1.03796\n",
      "[225]\tvalid_0's multi_logloss: 1.03968\tvalid_0's multi_logloss: 1.03968\n",
      "[226]\tvalid_0's multi_logloss: 1.04003\tvalid_0's multi_logloss: 1.04003\n",
      "[227]\tvalid_0's multi_logloss: 1.04148\tvalid_0's multi_logloss: 1.04148\n",
      "[228]\tvalid_0's multi_logloss: 1.04336\tvalid_0's multi_logloss: 1.04336\n",
      "[229]\tvalid_0's multi_logloss: 1.04549\tvalid_0's multi_logloss: 1.04549\n",
      "[230]\tvalid_0's multi_logloss: 1.04657\tvalid_0's multi_logloss: 1.04657\n",
      "[231]\tvalid_0's multi_logloss: 1.04731\tvalid_0's multi_logloss: 1.04731\n",
      "[232]\tvalid_0's multi_logloss: 1.04935\tvalid_0's multi_logloss: 1.04935\n",
      "[233]\tvalid_0's multi_logloss: 1.05098\tvalid_0's multi_logloss: 1.05098\n",
      "[234]\tvalid_0's multi_logloss: 1.05302\tvalid_0's multi_logloss: 1.05302\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's multi_logloss: 0.962893\tvalid_0's multi_logloss: 0.962893\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(ftr, target, test_size=0.2, random_state=156)\n",
    "\n",
    "lgbm_wrapper = LGBMClassifier(n_estimators=1000, num_leaves=100, subsample=0.8,\n",
    "                      min_child_samples=320, max_depth=30)\n",
    "\n",
    "evals = [(ftr, target)]\n",
    "lgbm_wrapper.fit(X_train, y_train, early_stopping_rounds=100, eval_metric='logloss', eval_set=evals, verbose=True)\n",
    "preds = lgbm_wrapper.predict(X_pivot_test)\n",
    "pred_proba = lgbm_wrapper.predict_proba(X_pivot_test)[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ruled-plymouth",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19479,
     "status": "ok",
     "timestamp": 1613799837669,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "ruled-plymouth",
    "outputId": "9d237465-b303-4c2e-958c-fc6a01969dca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(782, 61)\n"
     ]
    }
   ],
   "source": [
    "print(pred_proba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15rfozy-iKR",
   "metadata": {
    "id": "b15rfozy-iKR"
   },
   "source": [
    "# 앙상블 Voting을 위한 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ju6VstGdGmiu",
   "metadata": {
    "id": "Ju6VstGdGmiu"
   },
   "source": [
    "---------------------------------------\n",
    "### RandomForest 최적 Parameter 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sVD0aDC6Glq5",
   "metadata": {
    "executionInfo": {
     "elapsed": 525,
     "status": "ok",
     "timestamp": 1613802863337,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "sVD0aDC6Glq5"
   },
   "outputs": [],
   "source": [
    "def SCORES(y_val, pred, proba) :\n",
    "    #acc = accuracy_score(y_val, pred)\n",
    "    f1 = f1_score(y_val, pred, average='macro')\n",
    "    #print(y_val[:10])\n",
    "    #print(proba[:10])\n",
    "    auc = roc_auc_score(y_val, proba, average='macro', multi_class='ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51A3UBwJGltl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1613802866160,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "51A3UBwJGltl",
    "outputId": "33c4f36c-fd88-40f5-8726-abbec2769388"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(625,)\n",
      "(782, 61)\n",
      "(782,)\n"
     ]
    }
   ],
   "source": [
    "print(y_val.shape)\n",
    "print(pred_proba.shape)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "hIatKL8-HadH",
   "metadata": {
    "executionInfo": {
     "elapsed": 493,
     "status": "ok",
     "timestamp": 1613803265531,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "hIatKL8-HadH"
   },
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_jobs=-1, random_state=0, min_samples_leaf=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ozkkehHNGlwP",
   "metadata": {
    "executionInfo": {
     "elapsed": 491,
     "status": "ok",
     "timestamp": 1613803271468,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "ozkkehHNGlwP"
   },
   "outputs": [],
   "source": [
    "# 수정 필요\n",
    "my_hyper_param = {\n",
    "    \"n_estimators\"      :[700,800], # 700 \n",
    "    \"max_depth\"         :[15,17,19],  # 17\n",
    "    \"min_samples_leaf\"  :[1,3]  # 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "il-sLzVBGly2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "executionInfo": {
     "elapsed": 416515,
     "status": "error",
     "timestamp": 1613805006600,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "il-sLzVBGly2",
    "outputId": "92123825-b2c8-4090-e2a6-22411fdf7125"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-c7866236e973>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#scoring=make_scorer(recall_score, average='micro')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_estimator:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "gcv_model = GridSearchCV(rf_model, param_grid=my_hyper_param, scoring='roc_auc_ovr', refit=True, cv=5, verbose=0)\n",
    "#scoring=make_scorer(recall_score, average='micro')\n",
    "\n",
    "gcv_model.fit(ftr, target)\n",
    "\n",
    "print(\"best_estimator:\", gcv_model.best_estimator_)\n",
    "print(\"best_params:\",    gcv_model.best_params_)\n",
    "print(\"best_score:\" ,    gcv_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8kA6Dlc9tH6",
   "metadata": {
    "id": "b8kA6Dlc9tH6"
   },
   "source": [
    "### RandomForest 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "H9CnOIUfI5Dv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19580,
     "status": "ok",
     "timestamp": 1613805028019,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "H9CnOIUfI5Dv",
    "outputId": "9c2dc33b-8300-445a-a97d-48bb429ee0f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=17, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=700,\n",
       "                       n_jobs=-1, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = rf_model = RandomForestClassifier(n_jobs=-1, random_state=0, min_samples_leaf=1, n_estimators=700, max_depth=17)\n",
    "rfc.fit(ftr, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bXTgRy-98hdb",
   "metadata": {
    "id": "bXTgRy-98hdb"
   },
   "source": [
    "### XGBOOST 최적 Parameter 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BpBRKlTbSP3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5203849,
     "status": "ok",
     "timestamp": 1613710813118,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "BpBRKlTbSP3c",
    "outputId": "8a663600-3eee-4777-848c-9686a3b2c383"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed: 38.1min\n",
      "[Parallel(n_jobs=5)]: Done  90 out of  90 | elapsed: 85.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search are: {'learning_rate': 0.05, 'max_depth': 8, 'n_estimators': 350, 'objective': 'binary:logistic', 'seed': 1337}\n"
     ]
    }
   ],
   "source": [
    "estimator = XGBClassifier()\n",
    " \n",
    "parameters = {\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05, 0.1], #so called `eta` value 0.05\n",
    "              'max_depth': [6,8,10],    # 8\n",
    "              'n_estimators': [300,350,400],    # 350 \n",
    "              'seed': [1337]}\n",
    "\n",
    "clf = GridSearchCV(estimator, parameters, n_jobs=5, \n",
    "                   cv=5, \n",
    "                   scoring='roc_auc_ovr',\n",
    "                   verbose=2, refit=True)\n",
    " \n",
    "clf.fit(ftr, target)\n",
    "print('Best parameters found by grid search are:', clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "km-umHGB9NCI",
   "metadata": {
    "id": "km-umHGB9NCI"
   },
   "source": [
    "### XGBOOST 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "beFgCeeuSP6P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56489,
     "status": "ok",
     "timestamp": 1613805088626,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "beFgCeeuSP6P",
    "outputId": "7cb0f4a3-91f1-4a44-aa13-60ceb57ae39c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7, gamma=0,\n",
       "              learning_rate=0.05, max_delta_step=0, max_depth=8,\n",
       "              min_child_weight=11, missing=-999, n_estimators=350, n_jobs=1,\n",
       "              nthread=4, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1337,\n",
       "              silent=1, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = XGBClassifier()\n",
    "xgb = XGBClassifier(colsample_bytree= 0.7, learning_rate= 0.05, max_depth= 8, min_child_weight= 11, missing= -999, n_estimators= 350, nthread= 4, objective= 'binary:logistic', seed= 1337, silent= 1, subsample= 0.8)\n",
    "xgb.fit(ftr, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divdt-DwFBTg",
   "metadata": {
    "id": "divdt-DwFBTg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38vFco-g95tv",
   "metadata": {
    "id": "38vFco-g95tv"
   },
   "source": [
    "### LGBM 최적 Parameter 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wTjaLQhrSQBO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1079237,
     "status": "ok",
     "timestamp": 1613697290820,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "wTjaLQhrSQBO",
    "outputId": "4aa754ef-a631-4cd7-9573-0195c03eba5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search are: {'learning_rate': 0.05, 'n_estimators': 1100}\n"
     ]
    }
   ],
   "source": [
    "estimator = LGBMClassifier(num_leaves=2)\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.05, 0.5],\n",
    "    'n_estimators': [1100]    # 1100 이상 확인 필요\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid, cv=5, scoring='roc_auc_ovr')\n",
    "\n",
    "grid.fit(ftr, target)\n",
    "\n",
    "print('Best parameters found by grid search are:', grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K2f3fioa-D7A",
   "metadata": {
    "id": "K2f3fioa-D7A"
   },
   "source": [
    "### LGBM 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3u7cQQ2UGl5G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79688,
     "status": "ok",
     "timestamp": 1613805179137,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "3u7cQQ2UGl5G",
    "outputId": "59fc9a15-f113-4a5a-d64f-abac58ebe14c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 2.68286\tvalid_0's multi_logloss: 2.68286\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\tvalid_0's multi_logloss: 2.61883\tvalid_0's multi_logloss: 2.61883\n",
      "[3]\tvalid_0's multi_logloss: 2.56097\tvalid_0's multi_logloss: 2.56097\n",
      "[4]\tvalid_0's multi_logloss: 2.50912\tvalid_0's multi_logloss: 2.50912\n",
      "[5]\tvalid_0's multi_logloss: 2.46081\tvalid_0's multi_logloss: 2.46081\n",
      "[6]\tvalid_0's multi_logloss: 2.41518\tvalid_0's multi_logloss: 2.41518\n",
      "[7]\tvalid_0's multi_logloss: 2.37265\tvalid_0's multi_logloss: 2.37265\n",
      "[8]\tvalid_0's multi_logloss: 2.33277\tvalid_0's multi_logloss: 2.33277\n",
      "[9]\tvalid_0's multi_logloss: 2.29567\tvalid_0's multi_logloss: 2.29567\n",
      "[10]\tvalid_0's multi_logloss: 2.26031\tvalid_0's multi_logloss: 2.26031\n",
      "[11]\tvalid_0's multi_logloss: 2.22525\tvalid_0's multi_logloss: 2.22525\n",
      "[12]\tvalid_0's multi_logloss: 2.19131\tvalid_0's multi_logloss: 2.19131\n",
      "[13]\tvalid_0's multi_logloss: 2.15924\tvalid_0's multi_logloss: 2.15924\n",
      "[14]\tvalid_0's multi_logloss: 2.12747\tvalid_0's multi_logloss: 2.12747\n",
      "[15]\tvalid_0's multi_logloss: 2.09805\tvalid_0's multi_logloss: 2.09805\n",
      "[16]\tvalid_0's multi_logloss: 2.06896\tvalid_0's multi_logloss: 2.06896\n",
      "[17]\tvalid_0's multi_logloss: 2.04121\tvalid_0's multi_logloss: 2.04121\n",
      "[18]\tvalid_0's multi_logloss: 2.0134\tvalid_0's multi_logloss: 2.0134\n",
      "[19]\tvalid_0's multi_logloss: 1.98499\tvalid_0's multi_logloss: 1.98499\n",
      "[20]\tvalid_0's multi_logloss: 1.95908\tvalid_0's multi_logloss: 1.95908\n",
      "[21]\tvalid_0's multi_logloss: 1.93361\tvalid_0's multi_logloss: 1.93361\n",
      "[22]\tvalid_0's multi_logloss: 1.90889\tvalid_0's multi_logloss: 1.90889\n",
      "[23]\tvalid_0's multi_logloss: 1.88391\tvalid_0's multi_logloss: 1.88391\n",
      "[24]\tvalid_0's multi_logloss: 1.86088\tvalid_0's multi_logloss: 1.86088\n",
      "[25]\tvalid_0's multi_logloss: 1.83746\tvalid_0's multi_logloss: 1.83746\n",
      "[26]\tvalid_0's multi_logloss: 1.81512\tvalid_0's multi_logloss: 1.81512\n",
      "[27]\tvalid_0's multi_logloss: 1.79415\tvalid_0's multi_logloss: 1.79415\n",
      "[28]\tvalid_0's multi_logloss: 1.7724\tvalid_0's multi_logloss: 1.7724\n",
      "[29]\tvalid_0's multi_logloss: 1.75185\tvalid_0's multi_logloss: 1.75185\n",
      "[30]\tvalid_0's multi_logloss: 1.7309\tvalid_0's multi_logloss: 1.7309\n",
      "[31]\tvalid_0's multi_logloss: 1.7107\tvalid_0's multi_logloss: 1.7107\n",
      "[32]\tvalid_0's multi_logloss: 1.69081\tvalid_0's multi_logloss: 1.69081\n",
      "[33]\tvalid_0's multi_logloss: 1.67058\tvalid_0's multi_logloss: 1.67058\n",
      "[34]\tvalid_0's multi_logloss: 1.65222\tvalid_0's multi_logloss: 1.65222\n",
      "[35]\tvalid_0's multi_logloss: 1.63339\tvalid_0's multi_logloss: 1.63339\n",
      "[36]\tvalid_0's multi_logloss: 1.61486\tvalid_0's multi_logloss: 1.61486\n",
      "[37]\tvalid_0's multi_logloss: 1.59635\tvalid_0's multi_logloss: 1.59635\n",
      "[38]\tvalid_0's multi_logloss: 1.57771\tvalid_0's multi_logloss: 1.57771\n",
      "[39]\tvalid_0's multi_logloss: 1.55897\tvalid_0's multi_logloss: 1.55897\n",
      "[40]\tvalid_0's multi_logloss: 1.54092\tvalid_0's multi_logloss: 1.54092\n",
      "[41]\tvalid_0's multi_logloss: 1.52367\tvalid_0's multi_logloss: 1.52367\n",
      "[42]\tvalid_0's multi_logloss: 1.50696\tvalid_0's multi_logloss: 1.50696\n",
      "[43]\tvalid_0's multi_logloss: 1.48948\tvalid_0's multi_logloss: 1.48948\n",
      "[44]\tvalid_0's multi_logloss: 1.47301\tvalid_0's multi_logloss: 1.47301\n",
      "[45]\tvalid_0's multi_logloss: 1.45663\tvalid_0's multi_logloss: 1.45663\n",
      "[46]\tvalid_0's multi_logloss: 1.44141\tvalid_0's multi_logloss: 1.44141\n",
      "[47]\tvalid_0's multi_logloss: 1.42578\tvalid_0's multi_logloss: 1.42578\n",
      "[48]\tvalid_0's multi_logloss: 1.41045\tvalid_0's multi_logloss: 1.41045\n",
      "[49]\tvalid_0's multi_logloss: 1.3961\tvalid_0's multi_logloss: 1.3961\n",
      "[50]\tvalid_0's multi_logloss: 1.38125\tvalid_0's multi_logloss: 1.38125\n",
      "[51]\tvalid_0's multi_logloss: 1.36595\tvalid_0's multi_logloss: 1.36595\n",
      "[52]\tvalid_0's multi_logloss: 1.35181\tvalid_0's multi_logloss: 1.35181\n",
      "[53]\tvalid_0's multi_logloss: 1.33779\tvalid_0's multi_logloss: 1.33779\n",
      "[54]\tvalid_0's multi_logloss: 1.32391\tvalid_0's multi_logloss: 1.32391\n",
      "[55]\tvalid_0's multi_logloss: 1.30958\tvalid_0's multi_logloss: 1.30958\n",
      "[56]\tvalid_0's multi_logloss: 1.29588\tvalid_0's multi_logloss: 1.29588\n",
      "[57]\tvalid_0's multi_logloss: 1.28377\tvalid_0's multi_logloss: 1.28377\n",
      "[58]\tvalid_0's multi_logloss: 1.27031\tvalid_0's multi_logloss: 1.27031\n",
      "[59]\tvalid_0's multi_logloss: 1.25765\tvalid_0's multi_logloss: 1.25765\n",
      "[60]\tvalid_0's multi_logloss: 1.24475\tvalid_0's multi_logloss: 1.24475\n",
      "[61]\tvalid_0's multi_logloss: 1.23281\tvalid_0's multi_logloss: 1.23281\n",
      "[62]\tvalid_0's multi_logloss: 1.22033\tvalid_0's multi_logloss: 1.22033\n",
      "[63]\tvalid_0's multi_logloss: 1.20849\tvalid_0's multi_logloss: 1.20849\n",
      "[64]\tvalid_0's multi_logloss: 1.1963\tvalid_0's multi_logloss: 1.1963\n",
      "[65]\tvalid_0's multi_logloss: 1.18449\tvalid_0's multi_logloss: 1.18449\n",
      "[66]\tvalid_0's multi_logloss: 1.17308\tvalid_0's multi_logloss: 1.17308\n",
      "[67]\tvalid_0's multi_logloss: 1.16118\tvalid_0's multi_logloss: 1.16118\n",
      "[68]\tvalid_0's multi_logloss: 1.14953\tvalid_0's multi_logloss: 1.14953\n",
      "[69]\tvalid_0's multi_logloss: 1.13807\tvalid_0's multi_logloss: 1.13807\n",
      "[70]\tvalid_0's multi_logloss: 1.12759\tvalid_0's multi_logloss: 1.12759\n",
      "[71]\tvalid_0's multi_logloss: 1.11672\tvalid_0's multi_logloss: 1.11672\n",
      "[72]\tvalid_0's multi_logloss: 1.10555\tvalid_0's multi_logloss: 1.10555\n",
      "[73]\tvalid_0's multi_logloss: 1.09506\tvalid_0's multi_logloss: 1.09506\n",
      "[74]\tvalid_0's multi_logloss: 1.08408\tvalid_0's multi_logloss: 1.08408\n",
      "[75]\tvalid_0's multi_logloss: 1.07461\tvalid_0's multi_logloss: 1.07461\n",
      "[76]\tvalid_0's multi_logloss: 1.06479\tvalid_0's multi_logloss: 1.06479\n",
      "[77]\tvalid_0's multi_logloss: 1.05398\tvalid_0's multi_logloss: 1.05398\n",
      "[78]\tvalid_0's multi_logloss: 1.04404\tvalid_0's multi_logloss: 1.04404\n",
      "[79]\tvalid_0's multi_logloss: 1.03406\tvalid_0's multi_logloss: 1.03406\n",
      "[80]\tvalid_0's multi_logloss: 1.0249\tvalid_0's multi_logloss: 1.0249\n",
      "[81]\tvalid_0's multi_logloss: 1.01515\tvalid_0's multi_logloss: 1.01515\n",
      "[82]\tvalid_0's multi_logloss: 1.00578\tvalid_0's multi_logloss: 1.00578\n",
      "[83]\tvalid_0's multi_logloss: 0.996235\tvalid_0's multi_logloss: 0.996235\n",
      "[84]\tvalid_0's multi_logloss: 0.987112\tvalid_0's multi_logloss: 0.987112\n",
      "[85]\tvalid_0's multi_logloss: 0.977885\tvalid_0's multi_logloss: 0.977885\n",
      "[86]\tvalid_0's multi_logloss: 0.968623\tvalid_0's multi_logloss: 0.968623\n",
      "[87]\tvalid_0's multi_logloss: 0.959868\tvalid_0's multi_logloss: 0.959868\n",
      "[88]\tvalid_0's multi_logloss: 0.950403\tvalid_0's multi_logloss: 0.950403\n",
      "[89]\tvalid_0's multi_logloss: 0.941906\tvalid_0's multi_logloss: 0.941906\n",
      "[90]\tvalid_0's multi_logloss: 0.933422\tvalid_0's multi_logloss: 0.933422\n",
      "[91]\tvalid_0's multi_logloss: 0.924951\tvalid_0's multi_logloss: 0.924951\n",
      "[92]\tvalid_0's multi_logloss: 0.916897\tvalid_0's multi_logloss: 0.916897\n",
      "[93]\tvalid_0's multi_logloss: 0.90893\tvalid_0's multi_logloss: 0.90893\n",
      "[94]\tvalid_0's multi_logloss: 0.900364\tvalid_0's multi_logloss: 0.900364\n",
      "[95]\tvalid_0's multi_logloss: 0.89225\tvalid_0's multi_logloss: 0.89225\n",
      "[96]\tvalid_0's multi_logloss: 0.88458\tvalid_0's multi_logloss: 0.88458\n",
      "[97]\tvalid_0's multi_logloss: 0.876567\tvalid_0's multi_logloss: 0.876567\n",
      "[98]\tvalid_0's multi_logloss: 0.868859\tvalid_0's multi_logloss: 0.868859\n",
      "[99]\tvalid_0's multi_logloss: 0.861099\tvalid_0's multi_logloss: 0.861099\n",
      "[100]\tvalid_0's multi_logloss: 0.853894\tvalid_0's multi_logloss: 0.853894\n",
      "[101]\tvalid_0's multi_logloss: 0.846353\tvalid_0's multi_logloss: 0.846353\n",
      "[102]\tvalid_0's multi_logloss: 0.838914\tvalid_0's multi_logloss: 0.838914\n",
      "[103]\tvalid_0's multi_logloss: 0.831785\tvalid_0's multi_logloss: 0.831785\n",
      "[104]\tvalid_0's multi_logloss: 0.825135\tvalid_0's multi_logloss: 0.825135\n",
      "[105]\tvalid_0's multi_logloss: 0.817729\tvalid_0's multi_logloss: 0.817729\n",
      "[106]\tvalid_0's multi_logloss: 0.810604\tvalid_0's multi_logloss: 0.810604\n",
      "[107]\tvalid_0's multi_logloss: 0.803918\tvalid_0's multi_logloss: 0.803918\n",
      "[108]\tvalid_0's multi_logloss: 0.797315\tvalid_0's multi_logloss: 0.797315\n",
      "[109]\tvalid_0's multi_logloss: 0.790687\tvalid_0's multi_logloss: 0.790687\n",
      "[110]\tvalid_0's multi_logloss: 0.784049\tvalid_0's multi_logloss: 0.784049\n",
      "[111]\tvalid_0's multi_logloss: 0.777905\tvalid_0's multi_logloss: 0.777905\n",
      "[112]\tvalid_0's multi_logloss: 0.771133\tvalid_0's multi_logloss: 0.771133\n",
      "[113]\tvalid_0's multi_logloss: 0.764973\tvalid_0's multi_logloss: 0.764973\n",
      "[114]\tvalid_0's multi_logloss: 0.758515\tvalid_0's multi_logloss: 0.758515\n",
      "[115]\tvalid_0's multi_logloss: 0.752008\tvalid_0's multi_logloss: 0.752008\n",
      "[116]\tvalid_0's multi_logloss: 0.746083\tvalid_0's multi_logloss: 0.746083\n",
      "[117]\tvalid_0's multi_logloss: 0.740193\tvalid_0's multi_logloss: 0.740193\n",
      "[118]\tvalid_0's multi_logloss: 0.73436\tvalid_0's multi_logloss: 0.73436\n",
      "[119]\tvalid_0's multi_logloss: 0.728557\tvalid_0's multi_logloss: 0.728557\n",
      "[120]\tvalid_0's multi_logloss: 0.722823\tvalid_0's multi_logloss: 0.722823\n",
      "[121]\tvalid_0's multi_logloss: 0.716884\tvalid_0's multi_logloss: 0.716884\n",
      "[122]\tvalid_0's multi_logloss: 0.711419\tvalid_0's multi_logloss: 0.711419\n",
      "[123]\tvalid_0's multi_logloss: 0.706052\tvalid_0's multi_logloss: 0.706052\n",
      "[124]\tvalid_0's multi_logloss: 0.700536\tvalid_0's multi_logloss: 0.700536\n",
      "[125]\tvalid_0's multi_logloss: 0.694935\tvalid_0's multi_logloss: 0.694935\n",
      "[126]\tvalid_0's multi_logloss: 0.689794\tvalid_0's multi_logloss: 0.689794\n",
      "[127]\tvalid_0's multi_logloss: 0.685007\tvalid_0's multi_logloss: 0.685007\n",
      "[128]\tvalid_0's multi_logloss: 0.680021\tvalid_0's multi_logloss: 0.680021\n",
      "[129]\tvalid_0's multi_logloss: 0.674864\tvalid_0's multi_logloss: 0.674864\n",
      "[130]\tvalid_0's multi_logloss: 0.669401\tvalid_0's multi_logloss: 0.669401\n",
      "[131]\tvalid_0's multi_logloss: 0.664611\tvalid_0's multi_logloss: 0.664611\n",
      "[132]\tvalid_0's multi_logloss: 0.659957\tvalid_0's multi_logloss: 0.659957\n",
      "[133]\tvalid_0's multi_logloss: 0.654793\tvalid_0's multi_logloss: 0.654793\n",
      "[134]\tvalid_0's multi_logloss: 0.649643\tvalid_0's multi_logloss: 0.649643\n",
      "[135]\tvalid_0's multi_logloss: 0.645116\tvalid_0's multi_logloss: 0.645116\n",
      "[136]\tvalid_0's multi_logloss: 0.640543\tvalid_0's multi_logloss: 0.640543\n",
      "[137]\tvalid_0's multi_logloss: 0.635742\tvalid_0's multi_logloss: 0.635742\n",
      "[138]\tvalid_0's multi_logloss: 0.631209\tvalid_0's multi_logloss: 0.631209\n",
      "[139]\tvalid_0's multi_logloss: 0.626426\tvalid_0's multi_logloss: 0.626426\n",
      "[140]\tvalid_0's multi_logloss: 0.622093\tvalid_0's multi_logloss: 0.622093\n",
      "[141]\tvalid_0's multi_logloss: 0.617826\tvalid_0's multi_logloss: 0.617826\n",
      "[142]\tvalid_0's multi_logloss: 0.613583\tvalid_0's multi_logloss: 0.613583\n",
      "[143]\tvalid_0's multi_logloss: 0.609372\tvalid_0's multi_logloss: 0.609372\n",
      "[144]\tvalid_0's multi_logloss: 0.60483\tvalid_0's multi_logloss: 0.60483\n",
      "[145]\tvalid_0's multi_logloss: 0.600609\tvalid_0's multi_logloss: 0.600609\n",
      "[146]\tvalid_0's multi_logloss: 0.596414\tvalid_0's multi_logloss: 0.596414\n",
      "[147]\tvalid_0's multi_logloss: 0.592236\tvalid_0's multi_logloss: 0.592236\n",
      "[148]\tvalid_0's multi_logloss: 0.587863\tvalid_0's multi_logloss: 0.587863\n",
      "[149]\tvalid_0's multi_logloss: 0.583516\tvalid_0's multi_logloss: 0.583516\n",
      "[150]\tvalid_0's multi_logloss: 0.57972\tvalid_0's multi_logloss: 0.57972\n",
      "[151]\tvalid_0's multi_logloss: 0.575755\tvalid_0's multi_logloss: 0.575755\n",
      "[152]\tvalid_0's multi_logloss: 0.571889\tvalid_0's multi_logloss: 0.571889\n",
      "[153]\tvalid_0's multi_logloss: 0.567796\tvalid_0's multi_logloss: 0.567796\n",
      "[154]\tvalid_0's multi_logloss: 0.563582\tvalid_0's multi_logloss: 0.563582\n",
      "[155]\tvalid_0's multi_logloss: 0.559847\tvalid_0's multi_logloss: 0.559847\n",
      "[156]\tvalid_0's multi_logloss: 0.556029\tvalid_0's multi_logloss: 0.556029\n",
      "[157]\tvalid_0's multi_logloss: 0.552481\tvalid_0's multi_logloss: 0.552481\n",
      "[158]\tvalid_0's multi_logloss: 0.548811\tvalid_0's multi_logloss: 0.548811\n",
      "[159]\tvalid_0's multi_logloss: 0.54488\tvalid_0's multi_logloss: 0.54488\n",
      "[160]\tvalid_0's multi_logloss: 0.541353\tvalid_0's multi_logloss: 0.541353\n",
      "[161]\tvalid_0's multi_logloss: 0.538005\tvalid_0's multi_logloss: 0.538005\n",
      "[162]\tvalid_0's multi_logloss: 0.534237\tvalid_0's multi_logloss: 0.534237\n",
      "[163]\tvalid_0's multi_logloss: 0.531042\tvalid_0's multi_logloss: 0.531042\n",
      "[164]\tvalid_0's multi_logloss: 0.527669\tvalid_0's multi_logloss: 0.527669\n",
      "[165]\tvalid_0's multi_logloss: 0.524341\tvalid_0's multi_logloss: 0.524341\n",
      "[166]\tvalid_0's multi_logloss: 0.521133\tvalid_0's multi_logloss: 0.521133\n",
      "[167]\tvalid_0's multi_logloss: 0.517721\tvalid_0's multi_logloss: 0.517721\n",
      "[168]\tvalid_0's multi_logloss: 0.514512\tvalid_0's multi_logloss: 0.514512\n",
      "[169]\tvalid_0's multi_logloss: 0.511539\tvalid_0's multi_logloss: 0.511539\n",
      "[170]\tvalid_0's multi_logloss: 0.508567\tvalid_0's multi_logloss: 0.508567\n",
      "[171]\tvalid_0's multi_logloss: 0.505147\tvalid_0's multi_logloss: 0.505147\n",
      "[172]\tvalid_0's multi_logloss: 0.502215\tvalid_0's multi_logloss: 0.502215\n",
      "[173]\tvalid_0's multi_logloss: 0.498922\tvalid_0's multi_logloss: 0.498922\n",
      "[174]\tvalid_0's multi_logloss: 0.495874\tvalid_0's multi_logloss: 0.495874\n",
      "[175]\tvalid_0's multi_logloss: 0.492844\tvalid_0's multi_logloss: 0.492844\n",
      "[176]\tvalid_0's multi_logloss: 0.489919\tvalid_0's multi_logloss: 0.489919\n",
      "[177]\tvalid_0's multi_logloss: 0.48716\tvalid_0's multi_logloss: 0.48716\n",
      "[178]\tvalid_0's multi_logloss: 0.484468\tvalid_0's multi_logloss: 0.484468\n",
      "[179]\tvalid_0's multi_logloss: 0.481613\tvalid_0's multi_logloss: 0.481613\n",
      "[180]\tvalid_0's multi_logloss: 0.47897\tvalid_0's multi_logloss: 0.47897\n",
      "[181]\tvalid_0's multi_logloss: 0.476352\tvalid_0's multi_logloss: 0.476352\n",
      "[182]\tvalid_0's multi_logloss: 0.473537\tvalid_0's multi_logloss: 0.473537\n",
      "[183]\tvalid_0's multi_logloss: 0.470841\tvalid_0's multi_logloss: 0.470841\n",
      "[184]\tvalid_0's multi_logloss: 0.468241\tvalid_0's multi_logloss: 0.468241\n",
      "[185]\tvalid_0's multi_logloss: 0.465602\tvalid_0's multi_logloss: 0.465602\n",
      "[186]\tvalid_0's multi_logloss: 0.462822\tvalid_0's multi_logloss: 0.462822\n",
      "[187]\tvalid_0's multi_logloss: 0.460249\tvalid_0's multi_logloss: 0.460249\n",
      "[188]\tvalid_0's multi_logloss: 0.457772\tvalid_0's multi_logloss: 0.457772\n",
      "[189]\tvalid_0's multi_logloss: 0.455253\tvalid_0's multi_logloss: 0.455253\n",
      "[190]\tvalid_0's multi_logloss: 0.45281\tvalid_0's multi_logloss: 0.45281\n",
      "[191]\tvalid_0's multi_logloss: 0.450539\tvalid_0's multi_logloss: 0.450539\n",
      "[192]\tvalid_0's multi_logloss: 0.447986\tvalid_0's multi_logloss: 0.447986\n",
      "[193]\tvalid_0's multi_logloss: 0.44538\tvalid_0's multi_logloss: 0.44538\n",
      "[194]\tvalid_0's multi_logloss: 0.44312\tvalid_0's multi_logloss: 0.44312\n",
      "[195]\tvalid_0's multi_logloss: 0.440745\tvalid_0's multi_logloss: 0.440745\n",
      "[196]\tvalid_0's multi_logloss: 0.438208\tvalid_0's multi_logloss: 0.438208\n",
      "[197]\tvalid_0's multi_logloss: 0.435931\tvalid_0's multi_logloss: 0.435931\n",
      "[198]\tvalid_0's multi_logloss: 0.433607\tvalid_0's multi_logloss: 0.433607\n",
      "[199]\tvalid_0's multi_logloss: 0.431535\tvalid_0's multi_logloss: 0.431535\n",
      "[200]\tvalid_0's multi_logloss: 0.429326\tvalid_0's multi_logloss: 0.429326\n",
      "[201]\tvalid_0's multi_logloss: 0.427215\tvalid_0's multi_logloss: 0.427215\n",
      "[202]\tvalid_0's multi_logloss: 0.424768\tvalid_0's multi_logloss: 0.424768\n",
      "[203]\tvalid_0's multi_logloss: 0.422573\tvalid_0's multi_logloss: 0.422573\n",
      "[204]\tvalid_0's multi_logloss: 0.420446\tvalid_0's multi_logloss: 0.420446\n",
      "[205]\tvalid_0's multi_logloss: 0.418161\tvalid_0's multi_logloss: 0.418161\n",
      "[206]\tvalid_0's multi_logloss: 0.415808\tvalid_0's multi_logloss: 0.415808\n",
      "[207]\tvalid_0's multi_logloss: 0.413609\tvalid_0's multi_logloss: 0.413609\n",
      "[208]\tvalid_0's multi_logloss: 0.411685\tvalid_0's multi_logloss: 0.411685\n",
      "[209]\tvalid_0's multi_logloss: 0.409599\tvalid_0's multi_logloss: 0.409599\n",
      "[210]\tvalid_0's multi_logloss: 0.407476\tvalid_0's multi_logloss: 0.407476\n",
      "[211]\tvalid_0's multi_logloss: 0.405496\tvalid_0's multi_logloss: 0.405496\n",
      "[212]\tvalid_0's multi_logloss: 0.403504\tvalid_0's multi_logloss: 0.403504\n",
      "[213]\tvalid_0's multi_logloss: 0.40177\tvalid_0's multi_logloss: 0.40177\n",
      "[214]\tvalid_0's multi_logloss: 0.399907\tvalid_0's multi_logloss: 0.399907\n",
      "[215]\tvalid_0's multi_logloss: 0.397929\tvalid_0's multi_logloss: 0.397929\n",
      "[216]\tvalid_0's multi_logloss: 0.396085\tvalid_0's multi_logloss: 0.396085\n",
      "[217]\tvalid_0's multi_logloss: 0.39412\tvalid_0's multi_logloss: 0.39412\n",
      "[218]\tvalid_0's multi_logloss: 0.392456\tvalid_0's multi_logloss: 0.392456\n",
      "[219]\tvalid_0's multi_logloss: 0.390705\tvalid_0's multi_logloss: 0.390705\n",
      "[220]\tvalid_0's multi_logloss: 0.388986\tvalid_0's multi_logloss: 0.388986\n",
      "[221]\tvalid_0's multi_logloss: 0.387052\tvalid_0's multi_logloss: 0.387052\n",
      "[222]\tvalid_0's multi_logloss: 0.385156\tvalid_0's multi_logloss: 0.385156\n",
      "[223]\tvalid_0's multi_logloss: 0.383433\tvalid_0's multi_logloss: 0.383433\n",
      "[224]\tvalid_0's multi_logloss: 0.381672\tvalid_0's multi_logloss: 0.381672\n",
      "[225]\tvalid_0's multi_logloss: 0.379946\tvalid_0's multi_logloss: 0.379946\n",
      "[226]\tvalid_0's multi_logloss: 0.37817\tvalid_0's multi_logloss: 0.37817\n",
      "[227]\tvalid_0's multi_logloss: 0.376598\tvalid_0's multi_logloss: 0.376598\n",
      "[228]\tvalid_0's multi_logloss: 0.374689\tvalid_0's multi_logloss: 0.374689\n",
      "[229]\tvalid_0's multi_logloss: 0.372995\tvalid_0's multi_logloss: 0.372995\n",
      "[230]\tvalid_0's multi_logloss: 0.371461\tvalid_0's multi_logloss: 0.371461\n",
      "[231]\tvalid_0's multi_logloss: 0.369943\tvalid_0's multi_logloss: 0.369943\n",
      "[232]\tvalid_0's multi_logloss: 0.36831\tvalid_0's multi_logloss: 0.36831\n",
      "[233]\tvalid_0's multi_logloss: 0.366562\tvalid_0's multi_logloss: 0.366562\n",
      "[234]\tvalid_0's multi_logloss: 0.365137\tvalid_0's multi_logloss: 0.365137\n",
      "[235]\tvalid_0's multi_logloss: 0.36337\tvalid_0's multi_logloss: 0.36337\n",
      "[236]\tvalid_0's multi_logloss: 0.361779\tvalid_0's multi_logloss: 0.361779\n",
      "[237]\tvalid_0's multi_logloss: 0.360267\tvalid_0's multi_logloss: 0.360267\n",
      "[238]\tvalid_0's multi_logloss: 0.358894\tvalid_0's multi_logloss: 0.358894\n",
      "[239]\tvalid_0's multi_logloss: 0.357315\tvalid_0's multi_logloss: 0.357315\n",
      "[240]\tvalid_0's multi_logloss: 0.355878\tvalid_0's multi_logloss: 0.355878\n",
      "[241]\tvalid_0's multi_logloss: 0.354305\tvalid_0's multi_logloss: 0.354305\n",
      "[242]\tvalid_0's multi_logloss: 0.352987\tvalid_0's multi_logloss: 0.352987\n",
      "[243]\tvalid_0's multi_logloss: 0.351507\tvalid_0's multi_logloss: 0.351507\n",
      "[244]\tvalid_0's multi_logloss: 0.350109\tvalid_0's multi_logloss: 0.350109\n",
      "[245]\tvalid_0's multi_logloss: 0.348981\tvalid_0's multi_logloss: 0.348981\n",
      "[246]\tvalid_0's multi_logloss: 0.347755\tvalid_0's multi_logloss: 0.347755\n",
      "[247]\tvalid_0's multi_logloss: 0.34641\tvalid_0's multi_logloss: 0.34641\n",
      "[248]\tvalid_0's multi_logloss: 0.344936\tvalid_0's multi_logloss: 0.344936\n",
      "[249]\tvalid_0's multi_logloss: 0.343492\tvalid_0's multi_logloss: 0.343492\n",
      "[250]\tvalid_0's multi_logloss: 0.342181\tvalid_0's multi_logloss: 0.342181\n",
      "[251]\tvalid_0's multi_logloss: 0.340813\tvalid_0's multi_logloss: 0.340813\n",
      "[252]\tvalid_0's multi_logloss: 0.339496\tvalid_0's multi_logloss: 0.339496\n",
      "[253]\tvalid_0's multi_logloss: 0.338102\tvalid_0's multi_logloss: 0.338102\n",
      "[254]\tvalid_0's multi_logloss: 0.33688\tvalid_0's multi_logloss: 0.33688\n",
      "[255]\tvalid_0's multi_logloss: 0.335537\tvalid_0's multi_logloss: 0.335537\n",
      "[256]\tvalid_0's multi_logloss: 0.334311\tvalid_0's multi_logloss: 0.334311\n",
      "[257]\tvalid_0's multi_logloss: 0.333015\tvalid_0's multi_logloss: 0.333015\n",
      "[258]\tvalid_0's multi_logloss: 0.331766\tvalid_0's multi_logloss: 0.331766\n",
      "[259]\tvalid_0's multi_logloss: 0.330547\tvalid_0's multi_logloss: 0.330547\n",
      "[260]\tvalid_0's multi_logloss: 0.329506\tvalid_0's multi_logloss: 0.329506\n",
      "[261]\tvalid_0's multi_logloss: 0.328328\tvalid_0's multi_logloss: 0.328328\n",
      "[262]\tvalid_0's multi_logloss: 0.327143\tvalid_0's multi_logloss: 0.327143\n",
      "[263]\tvalid_0's multi_logloss: 0.325875\tvalid_0's multi_logloss: 0.325875\n",
      "[264]\tvalid_0's multi_logloss: 0.324744\tvalid_0's multi_logloss: 0.324744\n",
      "[265]\tvalid_0's multi_logloss: 0.32349\tvalid_0's multi_logloss: 0.32349\n",
      "[266]\tvalid_0's multi_logloss: 0.322454\tvalid_0's multi_logloss: 0.322454\n",
      "[267]\tvalid_0's multi_logloss: 0.321244\tvalid_0's multi_logloss: 0.321244\n",
      "[268]\tvalid_0's multi_logloss: 0.320158\tvalid_0's multi_logloss: 0.320158\n",
      "[269]\tvalid_0's multi_logloss: 0.319243\tvalid_0's multi_logloss: 0.319243\n",
      "[270]\tvalid_0's multi_logloss: 0.318016\tvalid_0's multi_logloss: 0.318016\n",
      "[271]\tvalid_0's multi_logloss: 0.317\tvalid_0's multi_logloss: 0.317\n",
      "[272]\tvalid_0's multi_logloss: 0.315863\tvalid_0's multi_logloss: 0.315863\n",
      "[273]\tvalid_0's multi_logloss: 0.314766\tvalid_0's multi_logloss: 0.314766\n",
      "[274]\tvalid_0's multi_logloss: 0.313853\tvalid_0's multi_logloss: 0.313853\n",
      "[275]\tvalid_0's multi_logloss: 0.312732\tvalid_0's multi_logloss: 0.312732\n",
      "[276]\tvalid_0's multi_logloss: 0.311823\tvalid_0's multi_logloss: 0.311823\n",
      "[277]\tvalid_0's multi_logloss: 0.310807\tvalid_0's multi_logloss: 0.310807\n",
      "[278]\tvalid_0's multi_logloss: 0.30986\tvalid_0's multi_logloss: 0.30986\n",
      "[279]\tvalid_0's multi_logloss: 0.308905\tvalid_0's multi_logloss: 0.308905\n",
      "[280]\tvalid_0's multi_logloss: 0.307894\tvalid_0's multi_logloss: 0.307894\n",
      "[281]\tvalid_0's multi_logloss: 0.306867\tvalid_0's multi_logloss: 0.306867\n",
      "[282]\tvalid_0's multi_logloss: 0.30578\tvalid_0's multi_logloss: 0.30578\n",
      "[283]\tvalid_0's multi_logloss: 0.30477\tvalid_0's multi_logloss: 0.30477\n",
      "[284]\tvalid_0's multi_logloss: 0.303797\tvalid_0's multi_logloss: 0.303797\n",
      "[285]\tvalid_0's multi_logloss: 0.30303\tvalid_0's multi_logloss: 0.30303\n",
      "[286]\tvalid_0's multi_logloss: 0.302098\tvalid_0's multi_logloss: 0.302098\n",
      "[287]\tvalid_0's multi_logloss: 0.301355\tvalid_0's multi_logloss: 0.301355\n",
      "[288]\tvalid_0's multi_logloss: 0.300395\tvalid_0's multi_logloss: 0.300395\n",
      "[289]\tvalid_0's multi_logloss: 0.299439\tvalid_0's multi_logloss: 0.299439\n",
      "[290]\tvalid_0's multi_logloss: 0.298638\tvalid_0's multi_logloss: 0.298638\n",
      "[291]\tvalid_0's multi_logloss: 0.297803\tvalid_0's multi_logloss: 0.297803\n",
      "[292]\tvalid_0's multi_logloss: 0.296918\tvalid_0's multi_logloss: 0.296918\n",
      "[293]\tvalid_0's multi_logloss: 0.296118\tvalid_0's multi_logloss: 0.296118\n",
      "[294]\tvalid_0's multi_logloss: 0.295292\tvalid_0's multi_logloss: 0.295292\n",
      "[295]\tvalid_0's multi_logloss: 0.294306\tvalid_0's multi_logloss: 0.294306\n",
      "[296]\tvalid_0's multi_logloss: 0.293556\tvalid_0's multi_logloss: 0.293556\n",
      "[297]\tvalid_0's multi_logloss: 0.292693\tvalid_0's multi_logloss: 0.292693\n",
      "[298]\tvalid_0's multi_logloss: 0.291888\tvalid_0's multi_logloss: 0.291888\n",
      "[299]\tvalid_0's multi_logloss: 0.291063\tvalid_0's multi_logloss: 0.291063\n",
      "[300]\tvalid_0's multi_logloss: 0.290205\tvalid_0's multi_logloss: 0.290205\n",
      "[301]\tvalid_0's multi_logloss: 0.289513\tvalid_0's multi_logloss: 0.289513\n",
      "[302]\tvalid_0's multi_logloss: 0.288884\tvalid_0's multi_logloss: 0.288884\n",
      "[303]\tvalid_0's multi_logloss: 0.288048\tvalid_0's multi_logloss: 0.288048\n",
      "[304]\tvalid_0's multi_logloss: 0.287348\tvalid_0's multi_logloss: 0.287348\n",
      "[305]\tvalid_0's multi_logloss: 0.286566\tvalid_0's multi_logloss: 0.286566\n",
      "[306]\tvalid_0's multi_logloss: 0.285778\tvalid_0's multi_logloss: 0.285778\n",
      "[307]\tvalid_0's multi_logloss: 0.285012\tvalid_0's multi_logloss: 0.285012\n",
      "[308]\tvalid_0's multi_logloss: 0.284435\tvalid_0's multi_logloss: 0.284435\n",
      "[309]\tvalid_0's multi_logloss: 0.283505\tvalid_0's multi_logloss: 0.283505\n",
      "[310]\tvalid_0's multi_logloss: 0.282809\tvalid_0's multi_logloss: 0.282809\n",
      "[311]\tvalid_0's multi_logloss: 0.282128\tvalid_0's multi_logloss: 0.282128\n",
      "[312]\tvalid_0's multi_logloss: 0.281291\tvalid_0's multi_logloss: 0.281291\n",
      "[313]\tvalid_0's multi_logloss: 0.280567\tvalid_0's multi_logloss: 0.280567\n",
      "[314]\tvalid_0's multi_logloss: 0.27976\tvalid_0's multi_logloss: 0.27976\n",
      "[315]\tvalid_0's multi_logloss: 0.279115\tvalid_0's multi_logloss: 0.279115\n",
      "[316]\tvalid_0's multi_logloss: 0.278485\tvalid_0's multi_logloss: 0.278485\n",
      "[317]\tvalid_0's multi_logloss: 0.277859\tvalid_0's multi_logloss: 0.277859\n",
      "[318]\tvalid_0's multi_logloss: 0.277249\tvalid_0's multi_logloss: 0.277249\n",
      "[319]\tvalid_0's multi_logloss: 0.276698\tvalid_0's multi_logloss: 0.276698\n",
      "[320]\tvalid_0's multi_logloss: 0.276013\tvalid_0's multi_logloss: 0.276013\n",
      "[321]\tvalid_0's multi_logloss: 0.275316\tvalid_0's multi_logloss: 0.275316\n",
      "[322]\tvalid_0's multi_logloss: 0.274789\tvalid_0's multi_logloss: 0.274789\n",
      "[323]\tvalid_0's multi_logloss: 0.274143\tvalid_0's multi_logloss: 0.274143\n",
      "[324]\tvalid_0's multi_logloss: 0.273478\tvalid_0's multi_logloss: 0.273478\n",
      "[325]\tvalid_0's multi_logloss: 0.272797\tvalid_0's multi_logloss: 0.272797\n",
      "[326]\tvalid_0's multi_logloss: 0.27212\tvalid_0's multi_logloss: 0.27212\n",
      "[327]\tvalid_0's multi_logloss: 0.27154\tvalid_0's multi_logloss: 0.27154\n",
      "[328]\tvalid_0's multi_logloss: 0.270912\tvalid_0's multi_logloss: 0.270912\n",
      "[329]\tvalid_0's multi_logloss: 0.270343\tvalid_0's multi_logloss: 0.270343\n",
      "[330]\tvalid_0's multi_logloss: 0.269805\tvalid_0's multi_logloss: 0.269805\n",
      "[331]\tvalid_0's multi_logloss: 0.269348\tvalid_0's multi_logloss: 0.269348\n",
      "[332]\tvalid_0's multi_logloss: 0.26887\tvalid_0's multi_logloss: 0.26887\n",
      "[333]\tvalid_0's multi_logloss: 0.268336\tvalid_0's multi_logloss: 0.268336\n",
      "[334]\tvalid_0's multi_logloss: 0.267915\tvalid_0's multi_logloss: 0.267915\n",
      "[335]\tvalid_0's multi_logloss: 0.267302\tvalid_0's multi_logloss: 0.267302\n",
      "[336]\tvalid_0's multi_logloss: 0.266811\tvalid_0's multi_logloss: 0.266811\n",
      "[337]\tvalid_0's multi_logloss: 0.266273\tvalid_0's multi_logloss: 0.266273\n",
      "[338]\tvalid_0's multi_logloss: 0.265805\tvalid_0's multi_logloss: 0.265805\n",
      "[339]\tvalid_0's multi_logloss: 0.265351\tvalid_0's multi_logloss: 0.265351\n",
      "[340]\tvalid_0's multi_logloss: 0.264738\tvalid_0's multi_logloss: 0.264738\n",
      "[341]\tvalid_0's multi_logloss: 0.264248\tvalid_0's multi_logloss: 0.264248\n",
      "[342]\tvalid_0's multi_logloss: 0.263705\tvalid_0's multi_logloss: 0.263705\n",
      "[343]\tvalid_0's multi_logloss: 0.263143\tvalid_0's multi_logloss: 0.263143\n",
      "[344]\tvalid_0's multi_logloss: 0.262633\tvalid_0's multi_logloss: 0.262633\n",
      "[345]\tvalid_0's multi_logloss: 0.262124\tvalid_0's multi_logloss: 0.262124\n",
      "[346]\tvalid_0's multi_logloss: 0.261675\tvalid_0's multi_logloss: 0.261675\n",
      "[347]\tvalid_0's multi_logloss: 0.26117\tvalid_0's multi_logloss: 0.26117\n",
      "[348]\tvalid_0's multi_logloss: 0.260723\tvalid_0's multi_logloss: 0.260723\n",
      "[349]\tvalid_0's multi_logloss: 0.260331\tvalid_0's multi_logloss: 0.260331\n",
      "[350]\tvalid_0's multi_logloss: 0.259925\tvalid_0's multi_logloss: 0.259925\n",
      "[351]\tvalid_0's multi_logloss: 0.259374\tvalid_0's multi_logloss: 0.259374\n",
      "[352]\tvalid_0's multi_logloss: 0.258962\tvalid_0's multi_logloss: 0.258962\n",
      "[353]\tvalid_0's multi_logloss: 0.258453\tvalid_0's multi_logloss: 0.258453\n",
      "[354]\tvalid_0's multi_logloss: 0.258099\tvalid_0's multi_logloss: 0.258099\n",
      "[355]\tvalid_0's multi_logloss: 0.257677\tvalid_0's multi_logloss: 0.257677\n",
      "[356]\tvalid_0's multi_logloss: 0.257294\tvalid_0's multi_logloss: 0.257294\n",
      "[357]\tvalid_0's multi_logloss: 0.256861\tvalid_0's multi_logloss: 0.256861\n",
      "[358]\tvalid_0's multi_logloss: 0.256495\tvalid_0's multi_logloss: 0.256495\n",
      "[359]\tvalid_0's multi_logloss: 0.256077\tvalid_0's multi_logloss: 0.256077\n",
      "[360]\tvalid_0's multi_logloss: 0.255719\tvalid_0's multi_logloss: 0.255719\n",
      "[361]\tvalid_0's multi_logloss: 0.255314\tvalid_0's multi_logloss: 0.255314\n",
      "[362]\tvalid_0's multi_logloss: 0.255035\tvalid_0's multi_logloss: 0.255035\n",
      "[363]\tvalid_0's multi_logloss: 0.254617\tvalid_0's multi_logloss: 0.254617\n",
      "[364]\tvalid_0's multi_logloss: 0.254265\tvalid_0's multi_logloss: 0.254265\n",
      "[365]\tvalid_0's multi_logloss: 0.254012\tvalid_0's multi_logloss: 0.254012\n",
      "[366]\tvalid_0's multi_logloss: 0.25361\tvalid_0's multi_logloss: 0.25361\n",
      "[367]\tvalid_0's multi_logloss: 0.253198\tvalid_0's multi_logloss: 0.253198\n",
      "[368]\tvalid_0's multi_logloss: 0.252968\tvalid_0's multi_logloss: 0.252968\n",
      "[369]\tvalid_0's multi_logloss: 0.252684\tvalid_0's multi_logloss: 0.252684\n",
      "[370]\tvalid_0's multi_logloss: 0.252411\tvalid_0's multi_logloss: 0.252411\n",
      "[371]\tvalid_0's multi_logloss: 0.252042\tvalid_0's multi_logloss: 0.252042\n",
      "[372]\tvalid_0's multi_logloss: 0.251782\tvalid_0's multi_logloss: 0.251782\n",
      "[373]\tvalid_0's multi_logloss: 0.25156\tvalid_0's multi_logloss: 0.25156\n",
      "[374]\tvalid_0's multi_logloss: 0.251268\tvalid_0's multi_logloss: 0.251268\n",
      "[375]\tvalid_0's multi_logloss: 0.250959\tvalid_0's multi_logloss: 0.250959\n",
      "[376]\tvalid_0's multi_logloss: 0.250677\tvalid_0's multi_logloss: 0.250677\n",
      "[377]\tvalid_0's multi_logloss: 0.250335\tvalid_0's multi_logloss: 0.250335\n",
      "[378]\tvalid_0's multi_logloss: 0.250087\tvalid_0's multi_logloss: 0.250087\n",
      "[379]\tvalid_0's multi_logloss: 0.24972\tvalid_0's multi_logloss: 0.24972\n",
      "[380]\tvalid_0's multi_logloss: 0.249471\tvalid_0's multi_logloss: 0.249471\n",
      "[381]\tvalid_0's multi_logloss: 0.24922\tvalid_0's multi_logloss: 0.24922\n",
      "[382]\tvalid_0's multi_logloss: 0.248968\tvalid_0's multi_logloss: 0.248968\n",
      "[383]\tvalid_0's multi_logloss: 0.248701\tvalid_0's multi_logloss: 0.248701\n",
      "[384]\tvalid_0's multi_logloss: 0.248322\tvalid_0's multi_logloss: 0.248322\n",
      "[385]\tvalid_0's multi_logloss: 0.24809\tvalid_0's multi_logloss: 0.24809\n",
      "[386]\tvalid_0's multi_logloss: 0.247922\tvalid_0's multi_logloss: 0.247922\n",
      "[387]\tvalid_0's multi_logloss: 0.247603\tvalid_0's multi_logloss: 0.247603\n",
      "[388]\tvalid_0's multi_logloss: 0.247405\tvalid_0's multi_logloss: 0.247405\n",
      "[389]\tvalid_0's multi_logloss: 0.247222\tvalid_0's multi_logloss: 0.247222\n",
      "[390]\tvalid_0's multi_logloss: 0.247003\tvalid_0's multi_logloss: 0.247003\n",
      "[391]\tvalid_0's multi_logloss: 0.246666\tvalid_0's multi_logloss: 0.246666\n",
      "[392]\tvalid_0's multi_logloss: 0.246529\tvalid_0's multi_logloss: 0.246529\n",
      "[393]\tvalid_0's multi_logloss: 0.2463\tvalid_0's multi_logloss: 0.2463\n",
      "[394]\tvalid_0's multi_logloss: 0.24602\tvalid_0's multi_logloss: 0.24602\n",
      "[395]\tvalid_0's multi_logloss: 0.245785\tvalid_0's multi_logloss: 0.245785\n",
      "[396]\tvalid_0's multi_logloss: 0.245547\tvalid_0's multi_logloss: 0.245547\n",
      "[397]\tvalid_0's multi_logloss: 0.245323\tvalid_0's multi_logloss: 0.245323\n",
      "[398]\tvalid_0's multi_logloss: 0.245124\tvalid_0's multi_logloss: 0.245124\n",
      "[399]\tvalid_0's multi_logloss: 0.244844\tvalid_0's multi_logloss: 0.244844\n",
      "[400]\tvalid_0's multi_logloss: 0.244643\tvalid_0's multi_logloss: 0.244643\n",
      "[401]\tvalid_0's multi_logloss: 0.244493\tvalid_0's multi_logloss: 0.244493\n",
      "[402]\tvalid_0's multi_logloss: 0.244278\tvalid_0's multi_logloss: 0.244278\n",
      "[403]\tvalid_0's multi_logloss: 0.244037\tvalid_0's multi_logloss: 0.244037\n",
      "[404]\tvalid_0's multi_logloss: 0.243885\tvalid_0's multi_logloss: 0.243885\n",
      "[405]\tvalid_0's multi_logloss: 0.243703\tvalid_0's multi_logloss: 0.243703\n",
      "[406]\tvalid_0's multi_logloss: 0.243449\tvalid_0's multi_logloss: 0.243449\n",
      "[407]\tvalid_0's multi_logloss: 0.243273\tvalid_0's multi_logloss: 0.243273\n",
      "[408]\tvalid_0's multi_logloss: 0.243111\tvalid_0's multi_logloss: 0.243111\n",
      "[409]\tvalid_0's multi_logloss: 0.242993\tvalid_0's multi_logloss: 0.242993\n",
      "[410]\tvalid_0's multi_logloss: 0.242774\tvalid_0's multi_logloss: 0.242774\n",
      "[411]\tvalid_0's multi_logloss: 0.242651\tvalid_0's multi_logloss: 0.242651\n",
      "[412]\tvalid_0's multi_logloss: 0.242625\tvalid_0's multi_logloss: 0.242625\n",
      "[413]\tvalid_0's multi_logloss: 0.24247\tvalid_0's multi_logloss: 0.24247\n",
      "[414]\tvalid_0's multi_logloss: 0.242393\tvalid_0's multi_logloss: 0.242393\n",
      "[415]\tvalid_0's multi_logloss: 0.242305\tvalid_0's multi_logloss: 0.242305\n",
      "[416]\tvalid_0's multi_logloss: 0.242042\tvalid_0's multi_logloss: 0.242042\n",
      "[417]\tvalid_0's multi_logloss: 0.242017\tvalid_0's multi_logloss: 0.242017\n",
      "[418]\tvalid_0's multi_logloss: 0.241871\tvalid_0's multi_logloss: 0.241871\n",
      "[419]\tvalid_0's multi_logloss: 0.241643\tvalid_0's multi_logloss: 0.241643\n",
      "[420]\tvalid_0's multi_logloss: 0.24139\tvalid_0's multi_logloss: 0.24139\n",
      "[421]\tvalid_0's multi_logloss: 0.241322\tvalid_0's multi_logloss: 0.241322\n",
      "[422]\tvalid_0's multi_logloss: 0.241183\tvalid_0's multi_logloss: 0.241183\n",
      "[423]\tvalid_0's multi_logloss: 0.241158\tvalid_0's multi_logloss: 0.241158\n",
      "[424]\tvalid_0's multi_logloss: 0.241017\tvalid_0's multi_logloss: 0.241017\n",
      "[425]\tvalid_0's multi_logloss: 0.240806\tvalid_0's multi_logloss: 0.240806\n",
      "[426]\tvalid_0's multi_logloss: 0.240683\tvalid_0's multi_logloss: 0.240683\n",
      "[427]\tvalid_0's multi_logloss: 0.240522\tvalid_0's multi_logloss: 0.240522\n",
      "[428]\tvalid_0's multi_logloss: 0.240442\tvalid_0's multi_logloss: 0.240442\n",
      "[429]\tvalid_0's multi_logloss: 0.240261\tvalid_0's multi_logloss: 0.240261\n",
      "[430]\tvalid_0's multi_logloss: 0.240153\tvalid_0's multi_logloss: 0.240153\n",
      "[431]\tvalid_0's multi_logloss: 0.240089\tvalid_0's multi_logloss: 0.240089\n",
      "[432]\tvalid_0's multi_logloss: 0.240062\tvalid_0's multi_logloss: 0.240062\n",
      "[433]\tvalid_0's multi_logloss: 0.239924\tvalid_0's multi_logloss: 0.239924\n",
      "[434]\tvalid_0's multi_logloss: 0.239846\tvalid_0's multi_logloss: 0.239846\n",
      "[435]\tvalid_0's multi_logloss: 0.239735\tvalid_0's multi_logloss: 0.239735\n",
      "[436]\tvalid_0's multi_logloss: 0.239459\tvalid_0's multi_logloss: 0.239459\n",
      "[437]\tvalid_0's multi_logloss: 0.23939\tvalid_0's multi_logloss: 0.23939\n",
      "[438]\tvalid_0's multi_logloss: 0.239266\tvalid_0's multi_logloss: 0.239266\n",
      "[439]\tvalid_0's multi_logloss: 0.239225\tvalid_0's multi_logloss: 0.239225\n",
      "[440]\tvalid_0's multi_logloss: 0.23905\tvalid_0's multi_logloss: 0.23905\n",
      "[441]\tvalid_0's multi_logloss: 0.238926\tvalid_0's multi_logloss: 0.238926\n",
      "[442]\tvalid_0's multi_logloss: 0.238774\tvalid_0's multi_logloss: 0.238774\n",
      "[443]\tvalid_0's multi_logloss: 0.238617\tvalid_0's multi_logloss: 0.238617\n",
      "[444]\tvalid_0's multi_logloss: 0.238492\tvalid_0's multi_logloss: 0.238492\n",
      "[445]\tvalid_0's multi_logloss: 0.238503\tvalid_0's multi_logloss: 0.238503\n",
      "[446]\tvalid_0's multi_logloss: 0.238461\tvalid_0's multi_logloss: 0.238461\n",
      "[447]\tvalid_0's multi_logloss: 0.238531\tvalid_0's multi_logloss: 0.238531\n",
      "[448]\tvalid_0's multi_logloss: 0.23842\tvalid_0's multi_logloss: 0.23842\n",
      "[449]\tvalid_0's multi_logloss: 0.238342\tvalid_0's multi_logloss: 0.238342\n",
      "[450]\tvalid_0's multi_logloss: 0.238284\tvalid_0's multi_logloss: 0.238284\n",
      "[451]\tvalid_0's multi_logloss: 0.238171\tvalid_0's multi_logloss: 0.238171\n",
      "[452]\tvalid_0's multi_logloss: 0.238012\tvalid_0's multi_logloss: 0.238012\n",
      "[453]\tvalid_0's multi_logloss: 0.237958\tvalid_0's multi_logloss: 0.237958\n",
      "[454]\tvalid_0's multi_logloss: 0.237925\tvalid_0's multi_logloss: 0.237925\n",
      "[455]\tvalid_0's multi_logloss: 0.237731\tvalid_0's multi_logloss: 0.237731\n",
      "[456]\tvalid_0's multi_logloss: 0.23766\tvalid_0's multi_logloss: 0.23766\n",
      "[457]\tvalid_0's multi_logloss: 0.237612\tvalid_0's multi_logloss: 0.237612\n",
      "[458]\tvalid_0's multi_logloss: 0.237479\tvalid_0's multi_logloss: 0.237479\n",
      "[459]\tvalid_0's multi_logloss: 0.237507\tvalid_0's multi_logloss: 0.237507\n",
      "[460]\tvalid_0's multi_logloss: 0.237401\tvalid_0's multi_logloss: 0.237401\n",
      "[461]\tvalid_0's multi_logloss: 0.2373\tvalid_0's multi_logloss: 0.2373\n",
      "[462]\tvalid_0's multi_logloss: 0.237323\tvalid_0's multi_logloss: 0.237323\n",
      "[463]\tvalid_0's multi_logloss: 0.237371\tvalid_0's multi_logloss: 0.237371\n",
      "[464]\tvalid_0's multi_logloss: 0.237304\tvalid_0's multi_logloss: 0.237304\n",
      "[465]\tvalid_0's multi_logloss: 0.237238\tvalid_0's multi_logloss: 0.237238\n",
      "[466]\tvalid_0's multi_logloss: 0.237193\tvalid_0's multi_logloss: 0.237193\n",
      "[467]\tvalid_0's multi_logloss: 0.23723\tvalid_0's multi_logloss: 0.23723\n",
      "[468]\tvalid_0's multi_logloss: 0.237236\tvalid_0's multi_logloss: 0.237236\n",
      "[469]\tvalid_0's multi_logloss: 0.237196\tvalid_0's multi_logloss: 0.237196\n",
      "[470]\tvalid_0's multi_logloss: 0.237191\tvalid_0's multi_logloss: 0.237191\n",
      "[471]\tvalid_0's multi_logloss: 0.237074\tvalid_0's multi_logloss: 0.237074\n",
      "[472]\tvalid_0's multi_logloss: 0.237049\tvalid_0's multi_logloss: 0.237049\n",
      "[473]\tvalid_0's multi_logloss: 0.237022\tvalid_0's multi_logloss: 0.237022\n",
      "[474]\tvalid_0's multi_logloss: 0.236997\tvalid_0's multi_logloss: 0.236997\n",
      "[475]\tvalid_0's multi_logloss: 0.237006\tvalid_0's multi_logloss: 0.237006\n",
      "[476]\tvalid_0's multi_logloss: 0.236994\tvalid_0's multi_logloss: 0.236994\n",
      "[477]\tvalid_0's multi_logloss: 0.236907\tvalid_0's multi_logloss: 0.236907\n",
      "[478]\tvalid_0's multi_logloss: 0.236802\tvalid_0's multi_logloss: 0.236802\n",
      "[479]\tvalid_0's multi_logloss: 0.236811\tvalid_0's multi_logloss: 0.236811\n",
      "[480]\tvalid_0's multi_logloss: 0.236755\tvalid_0's multi_logloss: 0.236755\n",
      "[481]\tvalid_0's multi_logloss: 0.23672\tvalid_0's multi_logloss: 0.23672\n",
      "[482]\tvalid_0's multi_logloss: 0.236697\tvalid_0's multi_logloss: 0.236697\n",
      "[483]\tvalid_0's multi_logloss: 0.236726\tvalid_0's multi_logloss: 0.236726\n",
      "[484]\tvalid_0's multi_logloss: 0.23669\tvalid_0's multi_logloss: 0.23669\n",
      "[485]\tvalid_0's multi_logloss: 0.23669\tvalid_0's multi_logloss: 0.23669\n",
      "[486]\tvalid_0's multi_logloss: 0.236554\tvalid_0's multi_logloss: 0.236554\n",
      "[487]\tvalid_0's multi_logloss: 0.236468\tvalid_0's multi_logloss: 0.236468\n",
      "[488]\tvalid_0's multi_logloss: 0.236418\tvalid_0's multi_logloss: 0.236418\n",
      "[489]\tvalid_0's multi_logloss: 0.236474\tvalid_0's multi_logloss: 0.236474\n",
      "[490]\tvalid_0's multi_logloss: 0.236539\tvalid_0's multi_logloss: 0.236539\n",
      "[491]\tvalid_0's multi_logloss: 0.236556\tvalid_0's multi_logloss: 0.236556\n",
      "[492]\tvalid_0's multi_logloss: 0.236602\tvalid_0's multi_logloss: 0.236602\n",
      "[493]\tvalid_0's multi_logloss: 0.236646\tvalid_0's multi_logloss: 0.236646\n",
      "[494]\tvalid_0's multi_logloss: 0.236587\tvalid_0's multi_logloss: 0.236587\n",
      "[495]\tvalid_0's multi_logloss: 0.236524\tvalid_0's multi_logloss: 0.236524\n",
      "[496]\tvalid_0's multi_logloss: 0.23664\tvalid_0's multi_logloss: 0.23664\n",
      "[497]\tvalid_0's multi_logloss: 0.236633\tvalid_0's multi_logloss: 0.236633\n",
      "[498]\tvalid_0's multi_logloss: 0.236547\tvalid_0's multi_logloss: 0.236547\n",
      "[499]\tvalid_0's multi_logloss: 0.236574\tvalid_0's multi_logloss: 0.236574\n",
      "[500]\tvalid_0's multi_logloss: 0.236583\tvalid_0's multi_logloss: 0.236583\n",
      "[501]\tvalid_0's multi_logloss: 0.23663\tvalid_0's multi_logloss: 0.23663\n",
      "[502]\tvalid_0's multi_logloss: 0.236707\tvalid_0's multi_logloss: 0.236707\n",
      "[503]\tvalid_0's multi_logloss: 0.236786\tvalid_0's multi_logloss: 0.236786\n",
      "[504]\tvalid_0's multi_logloss: 0.23671\tvalid_0's multi_logloss: 0.23671\n",
      "[505]\tvalid_0's multi_logloss: 0.236661\tvalid_0's multi_logloss: 0.236661\n",
      "[506]\tvalid_0's multi_logloss: 0.236694\tvalid_0's multi_logloss: 0.236694\n",
      "[507]\tvalid_0's multi_logloss: 0.236722\tvalid_0's multi_logloss: 0.236722\n",
      "[508]\tvalid_0's multi_logloss: 0.236758\tvalid_0's multi_logloss: 0.236758\n",
      "[509]\tvalid_0's multi_logloss: 0.236665\tvalid_0's multi_logloss: 0.236665\n",
      "[510]\tvalid_0's multi_logloss: 0.236725\tvalid_0's multi_logloss: 0.236725\n",
      "[511]\tvalid_0's multi_logloss: 0.236757\tvalid_0's multi_logloss: 0.236757\n",
      "[512]\tvalid_0's multi_logloss: 0.236809\tvalid_0's multi_logloss: 0.236809\n",
      "[513]\tvalid_0's multi_logloss: 0.236832\tvalid_0's multi_logloss: 0.236832\n",
      "[514]\tvalid_0's multi_logloss: 0.236755\tvalid_0's multi_logloss: 0.236755\n",
      "[515]\tvalid_0's multi_logloss: 0.236813\tvalid_0's multi_logloss: 0.236813\n",
      "[516]\tvalid_0's multi_logloss: 0.236832\tvalid_0's multi_logloss: 0.236832\n",
      "[517]\tvalid_0's multi_logloss: 0.236835\tvalid_0's multi_logloss: 0.236835\n",
      "[518]\tvalid_0's multi_logloss: 0.23697\tvalid_0's multi_logloss: 0.23697\n",
      "[519]\tvalid_0's multi_logloss: 0.23696\tvalid_0's multi_logloss: 0.23696\n",
      "[520]\tvalid_0's multi_logloss: 0.237003\tvalid_0's multi_logloss: 0.237003\n",
      "[521]\tvalid_0's multi_logloss: 0.237119\tvalid_0's multi_logloss: 0.237119\n",
      "[522]\tvalid_0's multi_logloss: 0.237107\tvalid_0's multi_logloss: 0.237107\n",
      "[523]\tvalid_0's multi_logloss: 0.237077\tvalid_0's multi_logloss: 0.237077\n",
      "[524]\tvalid_0's multi_logloss: 0.237034\tvalid_0's multi_logloss: 0.237034\n",
      "[525]\tvalid_0's multi_logloss: 0.237013\tvalid_0's multi_logloss: 0.237013\n",
      "[526]\tvalid_0's multi_logloss: 0.23711\tvalid_0's multi_logloss: 0.23711\n",
      "[527]\tvalid_0's multi_logloss: 0.237104\tvalid_0's multi_logloss: 0.237104\n",
      "[528]\tvalid_0's multi_logloss: 0.237187\tvalid_0's multi_logloss: 0.237187\n",
      "[529]\tvalid_0's multi_logloss: 0.237277\tvalid_0's multi_logloss: 0.237277\n",
      "[530]\tvalid_0's multi_logloss: 0.237328\tvalid_0's multi_logloss: 0.237328\n",
      "[531]\tvalid_0's multi_logloss: 0.23736\tvalid_0's multi_logloss: 0.23736\n",
      "[532]\tvalid_0's multi_logloss: 0.237477\tvalid_0's multi_logloss: 0.237477\n",
      "[533]\tvalid_0's multi_logloss: 0.237535\tvalid_0's multi_logloss: 0.237535\n",
      "[534]\tvalid_0's multi_logloss: 0.237493\tvalid_0's multi_logloss: 0.237493\n",
      "[535]\tvalid_0's multi_logloss: 0.237625\tvalid_0's multi_logloss: 0.237625\n",
      "[536]\tvalid_0's multi_logloss: 0.237673\tvalid_0's multi_logloss: 0.237673\n",
      "[537]\tvalid_0's multi_logloss: 0.237762\tvalid_0's multi_logloss: 0.237762\n",
      "[538]\tvalid_0's multi_logloss: 0.237876\tvalid_0's multi_logloss: 0.237876\n",
      "[539]\tvalid_0's multi_logloss: 0.237879\tvalid_0's multi_logloss: 0.237879\n",
      "[540]\tvalid_0's multi_logloss: 0.238003\tvalid_0's multi_logloss: 0.238003\n",
      "[541]\tvalid_0's multi_logloss: 0.238053\tvalid_0's multi_logloss: 0.238053\n",
      "[542]\tvalid_0's multi_logloss: 0.238072\tvalid_0's multi_logloss: 0.238072\n",
      "[543]\tvalid_0's multi_logloss: 0.23808\tvalid_0's multi_logloss: 0.23808\n",
      "[544]\tvalid_0's multi_logloss: 0.238082\tvalid_0's multi_logloss: 0.238082\n",
      "[545]\tvalid_0's multi_logloss: 0.238151\tvalid_0's multi_logloss: 0.238151\n",
      "[546]\tvalid_0's multi_logloss: 0.238198\tvalid_0's multi_logloss: 0.238198\n",
      "[547]\tvalid_0's multi_logloss: 0.238353\tvalid_0's multi_logloss: 0.238353\n",
      "[548]\tvalid_0's multi_logloss: 0.238376\tvalid_0's multi_logloss: 0.238376\n",
      "[549]\tvalid_0's multi_logloss: 0.238246\tvalid_0's multi_logloss: 0.238246\n",
      "[550]\tvalid_0's multi_logloss: 0.238327\tvalid_0's multi_logloss: 0.238327\n",
      "[551]\tvalid_0's multi_logloss: 0.238475\tvalid_0's multi_logloss: 0.238475\n",
      "[552]\tvalid_0's multi_logloss: 0.238567\tvalid_0's multi_logloss: 0.238567\n",
      "[553]\tvalid_0's multi_logloss: 0.238689\tvalid_0's multi_logloss: 0.238689\n",
      "[554]\tvalid_0's multi_logloss: 0.238715\tvalid_0's multi_logloss: 0.238715\n",
      "[555]\tvalid_0's multi_logloss: 0.238769\tvalid_0's multi_logloss: 0.238769\n",
      "[556]\tvalid_0's multi_logloss: 0.23878\tvalid_0's multi_logloss: 0.23878\n",
      "[557]\tvalid_0's multi_logloss: 0.238853\tvalid_0's multi_logloss: 0.238853\n",
      "[558]\tvalid_0's multi_logloss: 0.238859\tvalid_0's multi_logloss: 0.238859\n",
      "[559]\tvalid_0's multi_logloss: 0.238857\tvalid_0's multi_logloss: 0.238857\n",
      "[560]\tvalid_0's multi_logloss: 0.238907\tvalid_0's multi_logloss: 0.238907\n",
      "[561]\tvalid_0's multi_logloss: 0.238911\tvalid_0's multi_logloss: 0.238911\n",
      "[562]\tvalid_0's multi_logloss: 0.238967\tvalid_0's multi_logloss: 0.238967\n",
      "[563]\tvalid_0's multi_logloss: 0.239132\tvalid_0's multi_logloss: 0.239132\n",
      "[564]\tvalid_0's multi_logloss: 0.239268\tvalid_0's multi_logloss: 0.239268\n",
      "[565]\tvalid_0's multi_logloss: 0.239372\tvalid_0's multi_logloss: 0.239372\n",
      "[566]\tvalid_0's multi_logloss: 0.239425\tvalid_0's multi_logloss: 0.239425\n",
      "[567]\tvalid_0's multi_logloss: 0.239395\tvalid_0's multi_logloss: 0.239395\n",
      "[568]\tvalid_0's multi_logloss: 0.23949\tvalid_0's multi_logloss: 0.23949\n",
      "[569]\tvalid_0's multi_logloss: 0.239594\tvalid_0's multi_logloss: 0.239594\n",
      "[570]\tvalid_0's multi_logloss: 0.23967\tvalid_0's multi_logloss: 0.23967\n",
      "[571]\tvalid_0's multi_logloss: 0.239764\tvalid_0's multi_logloss: 0.239764\n",
      "[572]\tvalid_0's multi_logloss: 0.239836\tvalid_0's multi_logloss: 0.239836\n",
      "[573]\tvalid_0's multi_logloss: 0.239848\tvalid_0's multi_logloss: 0.239848\n",
      "[574]\tvalid_0's multi_logloss: 0.239941\tvalid_0's multi_logloss: 0.239941\n",
      "[575]\tvalid_0's multi_logloss: 0.240017\tvalid_0's multi_logloss: 0.240017\n",
      "[576]\tvalid_0's multi_logloss: 0.240185\tvalid_0's multi_logloss: 0.240185\n",
      "[577]\tvalid_0's multi_logloss: 0.240125\tvalid_0's multi_logloss: 0.240125\n",
      "[578]\tvalid_0's multi_logloss: 0.240269\tvalid_0's multi_logloss: 0.240269\n",
      "[579]\tvalid_0's multi_logloss: 0.240412\tvalid_0's multi_logloss: 0.240412\n",
      "[580]\tvalid_0's multi_logloss: 0.240516\tvalid_0's multi_logloss: 0.240516\n",
      "[581]\tvalid_0's multi_logloss: 0.240537\tvalid_0's multi_logloss: 0.240537\n",
      "[582]\tvalid_0's multi_logloss: 0.240625\tvalid_0's multi_logloss: 0.240625\n",
      "[583]\tvalid_0's multi_logloss: 0.240661\tvalid_0's multi_logloss: 0.240661\n",
      "[584]\tvalid_0's multi_logloss: 0.240613\tvalid_0's multi_logloss: 0.240613\n",
      "[585]\tvalid_0's multi_logloss: 0.24077\tvalid_0's multi_logloss: 0.24077\n",
      "[586]\tvalid_0's multi_logloss: 0.240796\tvalid_0's multi_logloss: 0.240796\n",
      "[587]\tvalid_0's multi_logloss: 0.240793\tvalid_0's multi_logloss: 0.240793\n",
      "[588]\tvalid_0's multi_logloss: 0.240932\tvalid_0's multi_logloss: 0.240932\n",
      "Early stopping, best iteration is:\n",
      "[488]\tvalid_0's multi_logloss: 0.236418\tvalid_0's multi_logloss: 0.236418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.05, max_depth=30,\n",
       "               min_child_samples=320, min_child_weight=0.001,\n",
       "               min_split_gain=0.0, n_estimators=1100, n_jobs=-1, num_leaves=100,\n",
       "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "               silent=True, subsample=0.8, subsample_for_bin=200000,\n",
       "               subsample_freq=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb = LGBMClassifier(n_estimators=1100, num_leaves=100, subsample=0.8,\n",
    "                      min_child_samples=320, max_depth=30, learning_rate=0.05)\n",
    "\n",
    "evals = [(ftr, target)]\n",
    "lgb.fit(X_train, y_train, early_stopping_rounds=100, eval_metric='logloss', eval_set=evals, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XV1AtMVT-Ih5",
   "metadata": {
    "id": "XV1AtMVT-Ih5"
   },
   "source": [
    "### 앙상블 Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "Bj6WlouyGl1A",
   "metadata": {
    "executionInfo": {
     "elapsed": 223865,
     "status": "ok",
     "timestamp": 1613805430977,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "Bj6WlouyGl1A"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "eclf = VotingClassifier(estimators=[('rfc', rfc), ('lgb', lgb), ('xgb', xgb)], voting='soft')\n",
    "eclf.fit(ftr, target)\n",
    "y_prob=eclf.predict_proba(X_pivot_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7HIYmxn597ai",
   "metadata": {
    "id": "7HIYmxn597ai"
   },
   "source": [
    "-------------------------------------\n",
    "### Stacking(CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "zCpQpSYz96P6",
   "metadata": {
    "executionInfo": {
     "elapsed": 776,
     "status": "ok",
     "timestamp": 1613802872063,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "zCpQpSYz96P6"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "-5rR-ro_KM31",
   "metadata": {
    "executionInfo": {
     "elapsed": 523,
     "status": "ok",
     "timestamp": 1613804202459,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "-5rR-ro_KM31"
   },
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "svc_model = SVC(probability=True)\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "rf_train_fold_predict  = np.zeros((X_train.shape[0], 1))\n",
    "svc_train_fold_predict = np.zeros((X_train.shape[0], 1))\n",
    "lr_train_fold_predict  = np.zeros((X_train.shape[0], 1))\n",
    "\n",
    "rf_test_predict  = np.zeros((X_val.shape[0], 5))\n",
    "svc_test_predict = np.zeros((X_val.shape[0], 5))\n",
    "lr_test_predict  = np.zeros((X_val.shape[0], 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ruIp99B096Sp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36184,
     "status": "ok",
     "timestamp": 1613803180394,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "ruIp99B096Sp",
    "outputId": "38a31f01-1a0c-4e74-c868-a5094349c56c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (500,) (500,) (500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (500,) (500,) (500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (500,) (500,) (500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 (500,) (500,) (500,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 (500,) (500,) (500,)\n"
     ]
    }
   ],
   "source": [
    "skFold = StratifiedKFold(n_splits=5, random_state=111, shuffle=True)\n",
    "for loop_cnt, (train_fold_idx, val_fold_idx) in enumerate(skFold.split(X_train, y_train)):\n",
    "    X_train_fold = X_train.iloc[train_fold_idx]\n",
    "    y_train_fold = y_train.iloc[train_fold_idx]\n",
    "    X_val_fold   = X_train.iloc[val_fold_idx]\n",
    "    y_val_fold   = y_train.iloc[val_fold_idx]\n",
    "    #--------------------------------------------------------- fit    X_train_fold, y_train_fold\n",
    "    rf_model.fit(X_train_fold, y_train_fold)\n",
    "    svc_model.fit(X_train_fold, y_train_fold)\n",
    "    lr_model.fit(X_train_fold, y_train_fold)\n",
    "    # --------------------------------------------------------- predict  X_val_fold\n",
    "    rf_pred_fold = rf_model.predict(X_val_fold)\n",
    "    svc_pred_fold = svc_model.predict(X_val_fold)\n",
    "    lr_pred_fold = lr_model.predict(X_val_fold)\n",
    "    print(loop_cnt, rf_pred_fold.shape,  svc_pred_fold.shape, lr_pred_fold.shape)\n",
    "\n",
    "    rf_train_fold_predict[val_fold_idx , :]   = rf_pred_fold.reshape(-1, 1)\n",
    "    svc_train_fold_predict[val_fold_idx , :]  = svc_pred_fold.reshape(-1, 1)\n",
    "    lr_train_fold_predict[val_fold_idx , :]   = lr_pred_fold.reshape(-1, 1)\n",
    "    # --------------------------------------------------------- predict   X_val\n",
    "    rf_pred_val  = rf_model.predict(X_val)\n",
    "    svc_pred_val = svc_model.predict(X_val)\n",
    "    lr_pred_val  = lr_model.predict(X_val)\n",
    "\n",
    "    rf_test_predict[:, loop_cnt]  = rf_pred_val\n",
    "    svc_test_predict[:, loop_cnt] = svc_pred_val\n",
    "    lr_test_predict[:, loop_cnt]  = lr_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "qryRMYsP96MA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 509,
     "status": "ok",
     "timestamp": 1613803219169,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "qryRMYsP96MA",
    "outputId": "ee323e60-aade-4e91-b1b1-ffec3cac5105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(625,)\n",
      "(625, 1)\n",
      "(625,)\n",
      "(625, 1)\n",
      "(625,)\n",
      "(625, 1)\n"
     ]
    }
   ],
   "source": [
    "rf_test_predict_mean = np.mean(rf_test_predict, axis=1)\n",
    "print(rf_test_predict_mean.shape)\n",
    "rf_test_predict_mean = rf_test_predict_mean.reshape(-1, 1)\n",
    "print(rf_test_predict_mean.shape)\n",
    "\n",
    "svc_test_predict_mean = np.mean(svc_test_predict, axis=1)\n",
    "print(svc_test_predict_mean.shape)\n",
    "svc_test_predict_mean = svc_test_predict_mean.reshape(-1, 1)\n",
    "print(svc_test_predict_mean.shape)\n",
    "\n",
    "lr_test_predict_mean = np.mean(lr_test_predict, axis=1)\n",
    "print(lr_test_predict_mean.shape)\n",
    "lr_test_predict_mean = lr_test_predict_mean.reshape(-1, 1)\n",
    "print(lr_test_predict_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "Q7evMIjS96U3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1613804120471,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "Q7evMIjS96U3",
    "outputId": "125a97fe-a3d8-4c17-d8c5-4226b0a7ddd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 3)\n",
      "(625, 3)\n",
      "(2500,)\n",
      "(782, 43)\n"
     ]
    }
   ],
   "source": [
    "new_train_data = np.concatenate([rf_train_fold_predict, svc_train_fold_predict, lr_train_fold_predict], axis=1)\n",
    "new_test_mean = np.concatenate([rf_test_predict_mean, svc_test_predict_mean, lr_test_predict_mean], axis=1)\n",
    "print(new_train_data.shape)\n",
    "print(new_test_mean.shape)\n",
    "print(y_train.shape)\n",
    "print(X_pivot_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "nhVnmJHH96Ji",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 49161,
     "status": "error",
     "timestamp": 1613804038827,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "nhVnmJHH96Ji",
    "outputId": "13a4dfbd-17f2-43ba-8277-b297109c66ca"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-5cf3c07f1400>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0meclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rfc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'lgb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'xgb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'soft'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0meclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pivot_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36m_predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;34m\"\"\"Predict class probabilities for X in 'soft' voting.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         avg = np.average(self._collect_probas(X), axis=0,\n\u001b[0m\u001b[1;32m    260\u001b[0m                          weights=self._weights_not_none)\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36m_collect_probas\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;34m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;34m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    389\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 3 and input n_features is 43 "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "eclf = VotingClassifier(estimators=[('rfc', rfc), ('lgb', lgb), ('xgb', xgb)], voting='soft')\n",
    "eclf.fit(new_train_data, y_train)\n",
    "y_prob=eclf.predict_proba(X_pivot_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hFSGLfd796G9",
   "metadata": {
    "id": "hFSGLfd796G9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6WtCdujN96Ej",
   "metadata": {
    "id": "6WtCdujN96Ej"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zysrpXoU96Bv",
   "metadata": {
    "id": "zysrpXoU96Bv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3qw8PRWOGl75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 716,
     "status": "ok",
     "timestamp": 1613805440405,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "3qw8PRWOGl75",
    "outputId": "05fd5a08-2b79-4ebc-fb5d-742041defda6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(782, 61)"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "limited-lottery",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1613805442323,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "limited-lottery",
    "outputId": "73daa504-537e-441d-f9b6-b4aa70442536"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3125</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.035807</td>\n",
       "      <td>0.166250</td>\n",
       "      <td>0.153824</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>0.327352</td>\n",
       "      <td>0.030346</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>0.094302</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.005671</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.004254</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.018254</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.020284</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.013174</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.051162</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.003587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3126</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.953555</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.005554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3127</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>0.431493</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.035973</td>\n",
       "      <td>0.005967</td>\n",
       "      <td>0.008118</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.014189</td>\n",
       "      <td>0.016464</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.053979</td>\n",
       "      <td>0.020275</td>\n",
       "      <td>0.005963</td>\n",
       "      <td>0.011627</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.023941</td>\n",
       "      <td>0.017108</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>0.010579</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.009730</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>0.049525</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.013466</td>\n",
       "      <td>0.023672</td>\n",
       "      <td>0.018723</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>0.024444</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.021623</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.081587</td>\n",
       "      <td>0.008781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3128</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.007578</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.940939</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.006522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3129</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.007587</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.952730</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.005541</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>3902</td>\n",
       "      <td>0.009399</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.054618</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.003177</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>0.006566</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.003547</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.008855</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.843901</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.011577</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.002923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>3903</td>\n",
       "      <td>0.002697</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.962274</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.003418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>3904</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.964702</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.005661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>3905</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.038986</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.002895</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>0.009441</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.830845</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.072112</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>0.000666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>3906</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.968781</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.006173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>782 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id         0         1         2  ...        57        58        59        60\n",
       "0    3125  0.002281  0.000375  0.002372  ...  0.001663  0.051162  0.000631  0.003587\n",
       "1    3126  0.001849  0.000107  0.000159  ...  0.005416  0.000250  0.000083  0.005554\n",
       "2    3127  0.004643  0.431493  0.000797  ...  0.000388  0.001307  0.081587  0.008781\n",
       "3    3128  0.001662  0.000829  0.002819  ...  0.001574  0.000083  0.000108  0.006522\n",
       "4    3129  0.004006  0.000072  0.000057  ...  0.001627  0.000067  0.000055  0.006507\n",
       "..    ...       ...       ...       ...  ...       ...       ...       ...       ...\n",
       "777  3902  0.009399  0.000165  0.000100  ...  0.002111  0.000327  0.000683  0.002923\n",
       "778  3903  0.002697  0.000142  0.000072  ...  0.001349  0.000070  0.000106  0.003418\n",
       "779  3904  0.001263  0.000113  0.000080  ...  0.001289  0.000083  0.000057  0.005661\n",
       "780  3905  0.000787  0.006008  0.000237  ...  0.000180  0.000081  0.001570  0.000666\n",
       "781  3906  0.000958  0.000116  0.000058  ...  0.001466  0.000169  0.000042  0.006173\n",
       "\n",
       "[782 rows x 62 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.iloc[:,1:] = y_prob\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "taken-excellence",
   "metadata": {
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1613805452601,
     "user": {
      "displayName": "니나노뭉",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-AMs6FybPdQDvfqrMik9Ee4kiDchwSNGskUwkzA=s64",
      "userId": "02453649485945443504"
     },
     "user_tz": -540
    },
    "id": "taken-excellence"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(d_path + 'baseline_rf1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-bronze",
   "metadata": {
    "id": "durable-bronze"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dacon_op.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
