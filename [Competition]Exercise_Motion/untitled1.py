# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bmhQseZXAlAvFM-hBlRPHpkg7Vl6VrXn
"""

# 분석
import pandas as pd
import numpy as np

# 시각화
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler


train = pd.read_csv('train_features.csv')
train_label = pd.read_csv('train_labels.csv')
test = pd.read_csv('test_features.csv')
submission = pd.read_csv('sample_submission.csv')

print(train_label.nunique(),"---------------------------------------")
train.shape, train_label.shape, test.shape, submission.shape

features = ['id', 'acc_x', 'acc_y', 'acc_z', 'gy_x', 'gy_y', 'gy_z']

df1 = train[features].groupby('id')
df1.head()

df1 = test[features].groupby('id')
df1.head()

print(train[features],test[features])
X_train = train[features]
X_test = test[features]

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_train = pd.DataFrame(X_train,  columns = features)
X_test = scaler.transform(X_test)
X_test = pd.DataFrame(X_test,  columns = features)

print(X_train)

print(X_test)

X_train = X_train.groupby('id').agg(['max', 'min', 'mean'])
print(X_train)
X_test = X_test.groupby('id').agg(['max', 'min', 'mean'])
print(X_test)

print(X_train.shape)
print(X_test.shape)

y_train = train_label['label']

from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(n_jobs=-1, random_state=0, min_samples_leaf=30)

rf_model.fit(X_train, y_train)

y_pred = rf_model.predict_proba(X_test)
y_pred

from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, roc_auc_score,precision_score,recall_score, roc_curve, classification_report,precision_recall_curve
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold

X_train , X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=111)


print(y_train.nunique(),"---------------------------------------")
print(y_val.nunique(),"---------------------------------------")


rf_model.fit(X_train, y_train)
pred = rf_model.predict(X_val)
proba = rf_model.predict_proba(X_val)
print(proba[:10])

# def SCORES(y_val, pred, proba) :
#     #acc = accuracy_score(y_val, pred)
#     f1 = f1_score(y_val, pred, average='macro')
#     print(y_val[:10])
#     print(proba[:10])
#     auc = roc_auc_score(y_val, proba, average='macro', multi_class='ovo')
#     # cf_matrix = confusion_matrix(y_val, pred)
#     # print(cf_matrix)

def SCORESww(y_val, pred, proba) :
    #acc = accuracy_score(y_val, pred)
    f1 = f1_score(y_val, pred, average='macro')
    auc = roc_auc_score(y_val, proba, average='macro', multi_class='ovo')
    print(auc)
    # cf_matrix = confusion_matrix(y_val, pred)
    # print(cf_matrix)

print(y_val.shape)
print(proba.shape)
print(pred.shape)

import sys
sys.version

SCORESww(y_val, pred, proba)

my_hyper_param = {
    "n_estimators"      :[300], 
    "max_depth"         :[3,5,7,9],
    "min_samples_leaf"  :[1,3,5],
}

from sklearn.metrics import make_scorer

gcv_model = GridSearchCV(rf_model, param_grid=my_hyper_param, scoring=make_scorer(SCORES), refit=True, cv=5, verbose=0)
#scoring=make_scorer(recall_score, average='micro')

gcv_model.fit(X_train, y_train)

print("best_estimator:", gcv_model.best_estimator_)
print("best_params:",    gcv_model.best_params_)
print("best_score:" ,    gcv_model.best_score_)

